

멀티스레드 애플리케이션의 기초는 프로세서 하드웨어에 의한 필요한 기능의 구현과 더불어 이들 기능을 애플리케이션이나 운영체제가 사용하도록 API로 변환하는 방식에 의해 마련된다. 이런 기초적 사항을 받아들이는 것은 멀티스레드 애플리케이션을 최적으로 구현하는 방법을 직관적으로 이해하는데 필수적이다.

2장에서 다룰 주제는 다음과 같다.(이들 내용 상당수는 운영체제에 나와있지만 다시 한번 다루도록 하겠다.)


- 멀티스레딩 개념을 지원하기 위한 프로세서 하드웨어 발전
- 이들 하드웨어 기능을 사용하기 위해 운영체제가 변경된 방식
- 다양한 아키텍처에서 메모리의 안정성과 메모리 모델 이면의 개념
- OS에 의한 다양한 프로세스 모델과 스레딩 모델 간의 차이점


---

### 프로세스와 스레드의 정의


기본적으로 운영체제에 있어서 프로세스는 각 스레드가 자신만의 상태와 변수를 처리하는 하나 또는 그 이상의 스레드로 구성된다. 이것은 하나 또는 그 이상의 스레드로 구성되는 프로세스(사용자) 실행을 지원하는 OS를 기본으로 하는 계층적 구성을 여길 수도 있다.

프로세스 간의 통신은 운영체제에 의해 제공되는 ==프로세스간 통신==(IPC,inter-process communication)으로 처리된다.


[그림]


OS 내의 각 프로세스는 고유한 상태를 갖는다. 프로세스 내에 각 스레드도 고유한 상태와 더불어 동일한 프로세스 내의 다른 스레드에 대한 상대적 상태도 가진다. ==IPC 기능==을 통해 프로세스가 서로 통신을 주고받는 반면 스레드는 동일한 프로세스 내의 다른 스레드와 다양한 방식으로 통신할 수 있다.

일반적으로 스레드 간의 공유 메모리를 가진다.




애플리케이션은 리눅스와 그 밖의 많은 운영체제에서 일반적으로 사용되는 ELF(Executable and Linkable Format)같은 특정 실행 가능 포맷 바이너리 데이터로부터 로드된다. ELF 바이너리인 경우 다음과 같은 여러 섹션이 존재한다.

- .bss
- .data
- .rodata
- .text


.bss 섹션 실행 파일에 순수 0의 값을 저장하는 것은 의미가 없기 때문에 기본적으로 바이너리 공간에 전혀 차지하지 않은 빈 배열을 가진 초기화되지 않는 메모리로 할당된다.

유사하게 초기화된 데이터를 가진 .data 섹션이 존재한다. 이 섹션은 전역 테이블과 변수 등을 가진다. 

마지막으로 그 이름이 암시하듯이 읽기 전용인, .rodata 섹션은 .data섹션과 유사하다. 이 섹션은 하드코딩된 문자열과 같은 것들을 포함한다.

.text 섹션에서 프로세서에서 실행되는 실제 애플리케이션 명령(코드)을 찾을 수 있다. 이들 모두가 운영체제에 의해 로드돼 프로세스를 생성한다. 이런 프로세스의 배치는 다음과 유사할 것이다.


[그림]


메모리 내의 최종 포맷은 PE 포맷 바이너리에서 시작하는 윈도우 프로세스를 포함해 어떤 OS에서라도 대략 비슷하겠지만, 이것은 프로세스가 ELF 포맷 바이너리로부터 시작할 때의 모습을 보여준다.

메모리 내의 최종 포맷은 PE 포멧 바이너리에서 시작하는 윈도우 프로세스를 포함해 기본적으로 어떤 OS에서라도 대략 비슷하겠지만, 이것은 프로세스가 ELF 포맷 바이너리로부터 시작할 때의 모습을 보여준다. 바이너리의 각 섹션은 명시된 크기에 따라 할당되는 BSS 섹션과 더불어 각각의 섹션에 로드된다.

.text 섹션은 다른 섹션과 함께 로드되고 로드가 완성되면 그 초기 명령이 실행돼 프로세스를 시작한다.


C++ 같은 시스템 언어에서 프로세스 내의 변수와 프로그램 상태 정보가 스택(변수는 범위 내에 존재한다)과 (new 연산자를 사용하는) 힙에 어떤 식으로 저장되는지 살펴볼 수 있다. 스택은(스레드별로 할당된) 메모리 섹션으로 그 크기는 운영체제와 구성에 따라 달라진다. 새로운 스레드를 생성할 때 프로그램에서 스택 크기를 설정할 수도 있다.

운영체제에서 프로세스는 그 크기는 일정하며 메모리 포인터의 크기에 의해 제한되는 메모리 주소의 블록으로 구성된다. 32-비트 OS의 경우 이 조건에 따라 블록은 4GB로 제한된다. 이 가상 메모리 공간 내에 OS는 기본스택과 힙을 할당한다. 이들 두 영역은 모든 메모리가 소진될 때까지 확장할 수가 있으며, 이때 프로세스가 추가적으로 메모리 할당을 시도하면 거부된다.

스택은 운영체제와 하드웨어 모드를 위한 개념이다. 본질적으로 스택은 스택 프레임의 모임(스택)이다. 각 스텍 프레임은 변수와 명령어, 태스크 실행과 관련된 그 밖의 다른 데이터로 구성된다.

하드웨어 관점에서 스택은 프로세서가 실행 인스턴스(프로그램이나 스레드)를 정의하는 방식은 태스크(x86)나 프로세스 상태(ARM)의 일부분이다. 이에 대한 좀 더 자세한 사항을 다음 절을 보아야 한다.


---


### x86에서의 태스크(32-비트와 64-비트)


태스크(task)는 인텔 IA-32 시스템 프로그래밍 가이드, 볼륨 3A에 다음과 같이 정의돼 있다.


"태스크는 프로세서가 디스패치하고 실행하고 중지시킬 수 있는 작업의 단위이다. 태스크는 프로그램이나 태스크, 프로세스, 운영체제 서비스 유틸리티, 인터럽트, 예외 핸들러, 커널, 익스큐티브 유틸리티를 실행하는데 사용될 수 있다."

"IA-32 아키텍쳐는 태스크의 상태를 저장하고, 실행을 위해 태스크를 디스패칭하고, 한 태스크에서 다른 태스크로 전환하기 위한 매커니즘을 제공한다. 보호 모드에서 동작할 때  모든 프로세서 실행은 태스크 내에서 이뤄진다. 간단한 시스템일지라도 최소 하나의 태스크는 정의해야 한다. 좀 더 복잡한 시스템은 프로세서의 태스크 관리 기능을 통해 멀티태스킹 애플리케이션을 지원할 수 있다."


IA-32(Intel x86) 메뉴얼에서 발췌한 이런 내용은 하드웨어 지원과 구현이 운영체제와 프로세스, 이들 프로세스 간의 전환을 어떻게 지원하는지 요약해준다.

여기서 알아야 할 중요한 사항은 프로세서에서는 프로세서나 스레드 같은 것은 존재하지 않는다는 것이다.==알고 있는 사항은 단지 일련의 명령으로 정의된 실행 스레드가 있다는 것이다.== 애플리케이션이 프로세스의 데이터 섹션 내에서 실행될 때 이들 명령은 메모리 어딘가에 로드되고 이들 명령의 현재 위치는 생성되는 변수 데이터(변수들)와 함께 추적이 이루어진다.


각 태스크는 또한 ==하드웨어에 의해 정의된 보호 링 내에서 실행==된다. OS 태스크는 일반적으로 링 0에서, 사용자 태스크는 링 3에서 실행한다. x86 아키텍처의 최근 OS에서 링 1과 2는 특수한 경우를 제외하면 사용되지 않는다. 이들 링 하드웨어에 의해 강제된 특권 레벨로서 커널과 유저 레벨 태스크의 엄격한 분리를 가능하게 해준다.

32-비트와 64-비트 태스크 용도의 태스크 구조체는 개념에 있어서 매우 유사하다. 이 구조체의 공식적 이름은 태스크 상태 구조체(TSS, Task State Structure)이다. 이 구조체는 32-비트x86 CPU에서 다음과 같다.


[그림]

다음과 같은 필드가 존재한다.

- SS0: 첫 번째 스택 세그먼트 셀렌터 필드
- ESP0: 첫 번째 SP필드

64-비트 x86_64 CPU의 경우 하드웨어 기반 태스크 전환이 이 모드에서 지원되지 않기 때문에 TSS 배치는 다소 다르다.


[그림]

여기서도 이름은 다르지만 유사한 관련 필드를 볼 수 있다.

- RSPn: 특권 레벨 0~2 용도의 SP
- ISTn: 인터럽트 스택 테이블 포인터

32-비트 모드의 x86에서조차도 CPU는 태스크 간에 하드웨어 기반의 전환을 지원한다. 대부분의 운영체제는 모드에 관계없이 CPU별 하나로 TSS 구조체를 사용해 소프트웨어에서 태스크 간의 실제 전환을 수행한다. 이것은 부분적으로 효율성(변경 포인터만을 스왑 아웃하는)에 기인하고 스레드나 프로세스의 우선순위 조정을 위해 프로세스/스레드에 의해 사용되는 CPU 시간 측정 같은 작업은 이런 방식으로만 가능한 것에 기인하기도 한다. 64-비트는 하드웨어 기반의 태스크 전환을 지원하지 않으므로 소프트웨어에서 이것을 수행하면 64-비트와 32-비트 시스템 간의 코드 이식이 간단해진다.


(일반적으로 인터럽트를 통해) 소프트웨어 기반의 태스크 전환 동안 ESP/RSP 등은 메모리에 저장되고 다음 스케줄될 태스크의 값으로 대체된다. 이는 실행이 재개되면 TSS 구조체는 새로운 태스크의 스택 포인터(SP)와 세그먼트 포인터(들), 레지스터 내용, 그 밖의 세부적인 것을 갖게 됨을 의미한다.


인터럽트의 출처는 하드웨어나 소프트웨어일 수 있다. 하드웨어 인터럽트는 자신들이 OS에 의한 관심을 가지기 위해 CPU에게 알리기 위한 용도로 일반적으로 장치에 의해 사용된다. 하드웨어 인터럽트를 호출하는 행위는 인터럽트 요청(Interrupt Request) 또는 IRQ로 부른다.


소프트웨어 인터럽트는 CPU 자체의 예외적 상황이나 CPU 명령 셋의 기능으로 기인할 수 있다. OS 커널에 의한 태스크 전환 행위는 소프트웨어 ==인터럽트==를 유발함으로 수행된다.


---


### ARM에서의 프로세스 상태

ARM 아키텍처에서 애플리케이션은 일반적으로 x86 아키텍처의 링 3에 비교되는 비특권 상태인 예외 레벨(Exception Level 0, EL0)에서 실행하며 OS 커널은 EL1에서 실행한다. ARMv7(AArch32, 32-비트) 아키텍처는 범용 레지스터 13에서 SP를 가진다. ARMv8(AArch64, 64-비트)의 경우 각 예외 수준(SP_EL0,SP_EL1)마다 전용 SP 레지스터가 구현돼 있다.


태스크 상태의 경우 ARM 아키텍처는 현재 프로그램 상태 레지스터(CPSR,Current Program State Register) 또는 저장 프로그램 상태 레지스터(SPSR, Saved Program State Register) 프로그램 상태 레지스터(PSR,Program State Register) 인스턴스를 사용한다. PSR은 프로세스 상태 정보의 추상적 개념으로 프로세스 상태(PSTATE,Process State)의 일부분이다.



---


### 스택

이전 절에서 살펴봤듯이 CPU 레지스터와 함께 스택은 태스크를 정의한다. 앞서 논의했듯이 이 ==스택은 스택 프레임으로 구성된다.== 이들 각 프레임은 태스크 실행에 대한 특정 인스턴스 (로컬) 변수와 인자, 데이터, 명령을 정의한다. 주목할 사항은 스택과 스텍 프레임이 주로 소프트웨어 개념일지라도 이것은 다수의 CPU 명령 세트에서 하드웨어 지원을 갖춘 현재 OS에서의 필수적 기능이라는 ㄱ서이다. 스택을 도식화하면 다음과 같을 것이다.



[그림]


SP(x86에서 ESP)는 추가적인 확장 베이스 포인터(EBP,Extended Base Pointer)(x86에서)와 함께 스택의 최상단을 가리킨다. 각 프레임은 OS에 의해 설정된 이전 프레임에 대한 참조(호출자 복귀 주소)를 가진다.

이것은 C++ 애플리케이션에 디버거를 사용할 때 역추적 기능에서 기본적으로 보이는 것으로 스택의 각 프레임은 최초의 스택 프레임부터 시작해 현재 프레임까지 나타낸다. 이때 각 개별 프레임의 세부적 사항을 살펴볼 수 있다.



---

### 멀티스레딩의 정의


**멀티프로세싱**은 ==다수의 물리적 프로세서가 존재하는 시스템에서 각 프로세서마다 하나의 태스크를 실행하는 것을 의미==하고, **멀티스레딩**은 ==단일 프로세서에 동시에 여러 태스크를 실행하는 것을 의미==한다.


따라서 멀티스레딩은 태스크가 모두 동시에 실행하고 있다는 착각을 불러일으킨다.


[그림]


멀티프로세싱과 멀티태스킹 간의 차이점은 후자는 단일 프로세서 코어에 여러 스레드를 실행하기 위해 타임-슬라이스(time-slices)를 사용하는 것이다. 이것은 멀티태스킹 시스템에서 태스크는 여전히 인터럽트될 수 있음에도 불구하고 동일한 CPU 코어에서 병행적 방식으로 태스크가 실행하지 않는다는 점에서 멀티스레딩과 다르다.

프로세스 개념과 프로세스 내에 포함된 스레드 간의 공유 메모리 공간은 소프트웨어 관점에서 멀티스레드 시스템의 핵심이 되는 부분이다. ==그렇지만 하드웨어는 OS에 대한 하나의 태스크만 볼 뿐 종종 이런 사실을 인지하지 못한다.== 멀티스레드 프로세스는 둘 또는 그 이상의 스레드를 포함하여 이들 각 스레드는 자신만의 고유한 태스크를 수행한다.


x86 프로세서의 인텔 하이퍼-스레딩(HT,Hyper-Threading)같은 다른 구현에서는 이런 멀티스레딩은 하드웨어 자체적으로 구현되며 이를 동시 멀티스레딩(SMT, Simultaneous multithreading)이라고 흔히 부른다. 자세한 사항은 '동시 멀티스레딩' 절을 참고하자.  

HT가 활성화될 때 각 물리적 CPU 코어는 두 개의 코어로서 OS에 제공된다. 하드웨어는 처리 코어의 다른 요소를 동시에 사용할 수 있는 동작을 스케줄링하면서 소위 말하는 이들 가상 코어에 할당된 태스크를 병행적으로 실행하고자 한다. 실제로 이는 운영체제나 최적화를 필요로 하는 애플리케이션이 없이도 성능에 괄목할만한 향상을 보여준다.

하드웨어는 자신이 수행하고 있는 명령에 대해 많은 세부적 사항을 인지하지 못하기 때문에 OS는 태스크의 실행을 추가적으로 최적화하기 위한 자신만의 스케줄링을 할 수 있다.

HT가 활성화됐다면 시각적으로 다음과 같이 볼 수 있다.


[그림]


이 그림에서 메모리 내(RAM)에 4개의 다른 태스크 명령을 볼 수 있다. 이들 중 두 태스크(스레드)는 동시에 실행이 되고 있으며 CPU 스케줄러(프론트앤드 부분에서)는 명령을 스케줄링해 가급적 많은 명령이 병렬적으로 실행될 수 있게 한다. 이런 작업이 불가능하면 실행 하드웨어가 유휴 상태가 되는 소위 말하는 **파이프라인 버블**(흰색 버블)이 발생한다.

내부 CPU 최적화와 함께 이런 방식은 초당 명령어(IPC,Instructions Per Second)수로 부르는 매우 높은 명령 처리량을 보여준다. 일반적으로 CPU의 GHz 수치 대신에 IPC 수치가 CPU의 순수 성능을 결정하는데 훨씬 중요하다.

---

### 플린의 종류


다른 유형의 컴퓨터 아키텍쳐는 1966년으로 가서 마이클 J. 플린 이 처음 제안한 시스템을 사용해 분류한다. ==이 분류 시스템은 4개의 범주를 인지하고서 입력과 출력 스트림 개수의 관점에서 처리 하드웨어의 능력을 정의한다.==

- **단일 명령, 단일 데이터**(SISD, Single Instruction Single Data): 하나의 명령이 하나의 데이터 스트림에 동작하기 위해 패치된다. CPU에 대한 전통적인 모델이다.
- **단일 명령, 복수 데이터**(SIMD, Single Instruction Multiple Data): 단일 명령이 여러 데이터 스트림에서 병렬로 동작한다. 그래픽 처리 유닛(GPU) 벡터 프로세서가 사용된다.
- **복수 명령, 단일 데이터**(MISD,Multiple Instruction Single Data): 다른 처리 유닛에 의해 동일한 동작인 동일한 데이터에 의해 수행돼 그 결과는 하드웨어 실패를 탐지하기 위해 마지막 부분에서 검증하는 중복 시스템에서 가장 흔히 사용된다. 항공 전자 시스템 등에서 주로 이용된다.
- **복수 명령, 복수 데이터**(MIMD, Multiple Instruction Multiple Data): 이 모델의 경우 멀티프로세싱 시스템이 매우 적합한다. 여러 프로세서에 걸친 다수의 스레드는 스트림 데이터를 처리한다. 이들 스레드는 SIMD 경우처럼 동일하지 않다.


이들은 범주가 멀티프로세싱이라는 하드웨어의 본질적 기능을 나타내고 있음을 알 수 있다. 소프트웨어 기법을 사용해 어떤 메소드라도 일반적인 SISD 유형의 아키텍처에서 하드웨어의 근사치에 근접할 수 있다. 하지만 이것은 멀티스레딩의 일부다.



---

### 대칭 대 비대칭 멀티프로세싱


지난 수십 년 동안 복수 처리 유닛을 가진 수많은 시스템이 만들어졌는데, 이는 크게 대칭형 멀티프로세싱(SMP,Symmetric Multiprocessing)과 비대칭형 멀티프로세싱(AMP,Asymmetric Multiprocessing) 시스템으로 나눌 수 있다.


AMP의 주요 정의 특성은 주 CPU의 주변 장치로 두 번째 프로세서가 연결된다는 것이다. 이는 부속 프로세서는 소프트웨어 제어를 실행하지 못하고 단지 사용자 애플리케이션만을 실행할 수 있음을 의미한다. 이런 접근법은 또한 상이한 아키텍처를 사용하는 CPU를 연결한다. 예를 들어 68k 기반의 아미가(Amiga) 시스템에서 x86 애플리케이션을 실행 할 수 있게 하는 데에도 사용될 수 있다.


SMP 시스템에서 각각의 CPU는 동일한 하드웨어 자원을 접근하는 동료들이며 협업 방식으로 구성된다. 최초에 SMP 시스템은 복수의 물리 CPU를 가졌지만 그 후로는 복수의 프로세서 코어가 하나의 CPU 칩에 통합됬다.


SMP는 가장 흔한 형태의 처리 방식으로 자리 잡았다.

기술적으로 시스템 내의 사운드와 네트워크 그래픽 프로세서는 CPU와 관련된 비대칭형 프로세서로 간주할 수 있다. 범용 GPU(GPGPU) 처리가 증가함에 따라 AMP는 좀 더 적절한 유형이 되고 있다.

---

### 느슨하거나 단단하게 결합된 멀티프로세싱

멀티프로세싱 시스템은 단일 시스템 내에 반드시 구현될 필요는 없으며 네트워크로 연결될 여러 시스템으로 구성될 수 있다. 이런 클러스터를 ==느슨하게 결합된 멀티프로세싱 시스템==이라고 한다.


이것은 같은 저수준의 버스와 고속의 버스 등을 사용하는 단일 인쇄 회로 보드(PCB)에 통합된 시스템인 단단하게 결합된 멀티프로세싱 시스템과는 상반적인 개념이다.


---

### 멀티프로세싱과 멀티스레딩의 결합


멀티-코어 CPU가 제공되는 거의 모든 최근 시스템은 둘 또는 그 이상의 처리 코어를 단일 프로세서 칩에 결합하는 형태로 멀티프로세싱과 멀티스레딩을 결합니다. 운영체제에서 이것이 의미하는 바는 최대 성능을 이끌어내기 위해 특정 코에서 태스크를 스케줄링하면서 여러 처리 코어에어솓 함께 태스크를 스케줄해야 한다는 것이다.


이는 **스케줄러**의 영역이며 나중에 나온다.


---

### 멀티스레딩 유형


멀티프로세싱과 마찬가지로 단 하나의 구현이 존재하는 것이 아니라 주요한 두 가지 구현이 있다. 이들 구현 간의 차이점은 프로세서가 한 사이클 동안에 동시에 실행할 수 있는 스레드의 최대 개수에 있다. 

멀티스레딩 구현의 주요 목적은 합리적으로 가능한 한 ==프로세서 하드웨어 사용량을 100%에 근접==하게 하는 것이다. 

다음 절에서는 두 종류의 멀티스레딩을 다룬다.


##### 시간적 멀티스레딩

**슈퍼-스레딩**으로도 알려져 있는 시간적 멀티스레딩(TMT, temporal multithreading)의 주요 하위 유형으로 **큰 단위**(coarse-grained), **작은 단위**(fine-grained, 또는 인터리브 interleaved)유형이 있다.

- 큰 단위: 태스크 간의 빠른 전환을 하면서 다른 태스크의 컨텍스트로 전환하기 전 자신의 컨텍스트를 저장한다.
- 작은 단위: 각 사이클마다 태스크를 전환해 다양한 태스크 명령으로 CPU 파이프라인을 구성한다. 이는 배력(barrel) 프로세서에서 구현된다. 


이들은 구현이 덜 복잡하면서도 특정 타이밍(엄격한 실시간 임베디드 시스템에서 유용한)을 보장한다는 측면에서 x86이나 그 밖의 다른 아키텍처에 비해 장점을 가진다.



#### 동시 멀티스레딩

즉 SMT는 x86과 ARM 아키텍처를 포함하는 슈퍼 스칼라 CPU(명령어 수준의 병렬성을 구현하는)에 구현된다. 특히 코어별로 병렬적으로 복수의 스레드를 실행하는 능력을 갖춘 SMT 정의 특징의 그 이름으로도 또한 알 수 있다.


일반적으로 코어별로 두 개의 스레드가 흔한 경우지만 일부 설계에서는 코어별로 8개까지의 동시 스레드를 지원하기도 한다. 복수의 스레드가 요구함으로 발생하는 명백한 충돌이 존재하고 이를 관리해야 하는 단점이 있을지라도 이 유형의 주요 장점은 스레드 간에 자원을 공유할 수 있다는 것이다. 하드웨어 자원의 중복이 없음으로 인해서 CPU 에너지가 좀 더 효율적이게 되는 또 다른 장점도 있다.


인텔 HT 기술은 2002년 펜티엄 4 CPU부터 기본 두 개의 스레드 SMT 엔진을 제공하는 인텔의 SMT 구현이라고 할 수 있다.



---

### 스케줄러


태스크-스케줄링 알고리즘 중에서, 일부는 최대 처리량을 추구하고 또 다른 일부는 지연 시간을 최소화하며, 응답 시간을 빠르게 할려는 알고리즘도 존재한다. 어떤 스케줄러가 최적의 선택지인지는 애플리케이션이 사용하는 시스템에 좌우한다.


- **데스크톱 시스템**: 스케줄러는 사용자에게 최상의 데스크톱 환경을 제공하기 위해 포어그라운드 애플리케이션에 백그라운드 애플리케이션보다 우선순위를 더 주는 방식으로 범용적으로 유지된다.
- **임베디드 시스템**: 실시간 시스템에서 산업용 애플리케이션은 타이밍 보장을 우선시할 수 있다. 실시간 시스템에서는 프로세스가 정확한 시각에 실행되도록 한다.


스케줄러 유형은 OS의 멀티태스킹 상태에도 좌우된다. **협력적 멀티태스킹 시스템**은 현재 실행 중인 프로세스를 다른 프로세스로 전환시킬 시점(실행 중인 프로세스가 양보를 하는 시점에 좌우된다.)에 관해 보장해줄 수 없기 때문이다.


**선점형 스케줄러**의 경우 프로세스는 자신이 전환된다는 사실을 인지하지 않아도 전환이 이루어진다. 따라서 스케줄러는 어떤 시점에 프로세스가 실행되는지에 대해 더 잘 제어할 수 있다.

[[OS별 스케줄링 알고리즘]]


---

### 예제 애플리케이션 추적


1장 '멀티스레딩 검토'의 예제 코드에서 몇몇 처리를 수행하기 위해 4개의 스레드를 사용하는 간단한 애플리케이션을 살펴보았다. 이번 절에서 이 애플리케이션에 대해 ==하드웨어==와==OS 관점==에서 살펴보도록 한다.

main 함수의 시작 부분 코드를 보면 하나의 정숫값을 포함하는 구조체를 생성한다.

``` c++

int main(){
values.push_back(42);


```

OS가 새로운 태스크와 관련 스택 구조체를 생성한 후 스택에 ==벡터 데이터 구조체==의 인스턴스(정수 유형에 맞게 사용자 정의된)가 할당된다. 이것의 크기는 바이너리 파일의 전역 데이터 섹션(ELF의 BSS)에 명시돼 있다.

애플리케이션이 main 함수를 사용해 실행이 시작되면 이 데이터 구조체는 새로운 정숫값을 가지도록 변경된다.

초기 데이터 값을 제공해 이제 4개의 스레드를 생성한다.

``` c++

	thread tr1(threadFnc, 1);
	thread tr2(threadFnc, 2);
	thread tr3(threadFnc, 3);
	thread tr4(threadFnc, 4);


```


이것은 OS 측면에서 새로운 데이터 구조체를 생성하고 새로운 스레드를 위한 스택을 할당한다는 것을 의미하고, 하드웨어 측면에서 하드웨어 기반의 태스크 전환이 사용되지 않는다면 아무런 변화도 없다는 것을 의미한다.


이 시점에서 OS의 스케줄러와 CPU는 이들 태스크(스레드)를 가능한 효율적이고도 빠르게 실행하기 위해 SMP와 SMT 등을 포함한 하드웨어 기능을 이용한 협업을 한다.


이 작업 이후 메인 스레드는 나머지 스레드가 실행을 멈출 때까지 대기한다.


``` c++
	tr1.join();
	tr2.join();
	tr3.join();
	tr4.join();
```

이들은 블록(blocking calls)로서 4개의 스레드(태스크)가 실행을 종료할 때까지 메인 스레드가 블록돼 있음으로 표시한다. 4개의 스레드의 실행이 모두 종료되는 시점에 OS의 스케줄러는 메인 스레드의 실행을 재개한다.


새롭게 생성된 각 스레드는 먼저 ==표준 출력에 동기적 접근을 보장==하기 위해 ==뮤텍스를 락 시켰음을 확인하는 문자열을 출력==한다.


``` c++
void threadFnc(int tid) {
	cout_mtx.lock();
	cout << "Starting thread " << tid << ".\n";
	cout_mtx.unlock();


```


뮤텍스는 기본적으로 힙의 스택에 저장돼 있는 하나의 값으로 원자적 동작을 사용해 접근된다. 이것은 몇몇 하드웨어 자원이 필요함을 의미한다. 이 뮤텍스를 사용해 태스크는 자신이 진행을 할 수 있는지 아니면 기다렸다가 다시 시도해야 하는지를 검사할 수 있다.


마지막 부분의 코드에서 이 뮤텍스 락은 표준 C++ 출력 스트림에 다른 스레드의 간섭없이 출력할 수 있게 해 준다.

이 작업 이후 벡터의 초깃값을 로컬 변수에 복사한다. 물론 이 작업 역시 동기적으로 이뤄짐을 보장해야 한다.

``` c++
	values_mtx.lock();
	int val = values[0];
	values_mtx.unlock();
```


뮤텍스 락이 다른 스레드의 접근을 염려하지 않고서 또는 해당 스레드가 사용 중인 동안에도 그 값의 변경을 염려하지 않고서 벡터 내의 첫 번째 값을 읽게 해 준다는 점을 제외하면 동일하다.

다음과 같이 난수를 생성하는 작업이 이어진다.


``` c++
	int rval = randGen(0, 10);

	val += rval;
```

여기서는 다음과 같은 randGen() 메소드를 사용한다.

``` c++
int randGen(const int& min, const int& max) {
	static thread_local mt19937 generator(hash<thread::id>() (this_thread::get_id()));

	uniform_int_distribution<int> distribution(min, max);
	return distribution(generator);
}
```


이 메소드는 **스레드 로컬 변수**를 사용한다는 점에서 흥미롭다. ==스레드 로컬 스토리==는 스래드 자신에게 한정적인 메모리 영역이다. **==이 영역은 전역변수에 대해서도 사용될 수 있음에도 불구하고 해당 스레드로 제한된다.==**


이는 여기서 사용된 것처럼 정적 변수에 매우 유용하다. 이 메소드를 사용할 때마다 이를 재초기화하기를 원하지 않고 또한 이 인스턴스를 스레드 간에 공유하는 것도 원하지 않으므로 generator 인스턴스를 정적으로 한다.

**스레드-로컬 정적 인스턴스를 사용**함으로서 두 가지 목적을 달성할 수 있다. 정적 인스턴스는 각 스레드별로 생성, 사용된다.


Thread 함수는 이제 동일한 일련의 뮤텍스가 락된 채로 새로운 값이 배열에 복사되면서 끝이 난다.

``` c++

	cout_mtx.lock();
	cout << "Thread" << tid << " adding" << rval << ". New value" << val << ".\n";
	cout_mtx.unlock();


	values_mtx.lock();
	values.push_back(val);
	values_mtx.unlock();

}
```

여기서 표준 출력 스트림에 대한 동기적 접근이 보이고 값 데이터 구조체에 대한 동기적 접근을 볼 수 있다.


---

### 상호 배제 구현

상호 배제(Mutual Exclusion)는 멀티스레드 애플리케이션 내의 데이터를 스레드로부터 안전하게 접근하도록 보장하는 원칙이다. 상호 배제는 하드웨어나 소프트웨어로 구현 가능하다. 상호 배제(뮤텍스)는 대부분의 구현에서 이 기능의 가장 기본적인 형태이다.


---

### 하드웨어

단일 프로세서(단일 프로세서 코어)에서 가장 단순한 하드웨어 기반의 구현은 non-SMT 시스템에서 인터럽트를 비활성화하고 따라서 태스크가 변경되는 것을 방지하는 것이다.

좀 더 일반적으로는 소위 바쁜-대기(busy-wait)원리를 사용한다. 이것은 프로세서가 데이터를 패치하는 방식 즈, 단 하나의 태스크만이 공유 메모리 내의 원자적 값(CPU 레지스터와 동일한 크기[또는 더 작은]의 변수)를 구하여 읽기-쓰기를 할 수 있음으로 인해 뮤텍스 이면에 있는 기본 원리이다. (이 원리는 8장에 나온다.)


예제의 코드가 뮤텍스를 수락할 때 수행되는 작업은 메모리의 원자적 영역의 값을 읽어서 락 상태의 값으로 이를 설정하려는 작업을 시도한다. 이것은 단일 동작이므로 언제라도 단 하나의 태스크만이 이 값을 변경할 수 있다. 그 이외의 태스크는 다음 그림에서 보듯이 바쁜-대기 사이클 내에서 접근이 획득될 때까지 기다려야 한다.


[그림]


---

### 소프트웨어

소프트웨어 정의 상호 배제 구현은 모두 **==바쁜-대기==** 에 기반한다. 한 예로 Dekker의 알고리즘을 들 수 있는데, 여기서는 상대편 프로세스가 임계 영역을 벗어나기를 대기하는 바쁜-대기를 사용하는 두 프로세스가 동기화할 수 있는 시스템을 정의한다.



``` sudo

variables

	wants_to_enter: array of 2 booleans
	turn:integer

wants_to_enter[0] <- false
wants_to_enter[1] <- false
turn <- 0 // or 1

p0:
	wants_to_enter[0]<-true
	while wants_to_enter[1]{
		if turn!=0{
		wants_to_enter[0]<-false
		while turn !=0{
		//busy wait
		}
		wants_to_enter[0] <-true
		}
		}
	// critical section
	
...
turn <-1
wants_to_enter[0]<-false
// remainder section

p1:

wants_to_enter[1] <-true


while wants_to_enter[0]{
	if turn!=1{

	wants_to_enter[1]<-false
	while turn!=1{
	// busy wait
	}
	wants_to_enter[1] <- true
	}
}
// critical section

...

turn <-0
wants_to_enter[1] <-false
// remainder section

```

이 알고리즘에서 프로세스는 임계 영역이 자신들의 순서인지 검사해 (프로세스 ID를 사용해) 임계 영억의 진입 의도를 표시하고 임계 영역의 진입 의도를 표시하고 임계 영역에 진입한 이후에는 임계 영역에 들어가고자 하는 자신들의 의도를 false로 설정한다.

프로세스는 진입을 원하지만 순서가 자신의 프로세스 ID와 일치하지 않는다면 조건이 true가 될 때까지 바쁜-대기를 해야만 한다.

소프트웨어 기반의 상호 배제 알고리즘의 큰 단점은 코드의 비순차적(OoO, Out-of-order)실행이 비활성화된 상태에서 동작한다는 것이다. OoO는 하드웨어가 명령어 실행을 최적화하기 위해 들어오는 명령어 순서를 재조정한다는 것을 의미한다. 이들 알고리즘에서는 다양한 단계가 순서대로 실행되야 하므로 OoO프로세서에서는 더 이상 동작하지 않는다.