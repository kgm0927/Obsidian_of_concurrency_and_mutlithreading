

**인스트럭션 레벨 병렬성**(instruction-level parallelism)은 이름 그대로 인스트럭션, 다시 말해 CPU의 레벨에서 병렬화를 수행하는 방법이다. 대단히 높은 수준의 최적화를 할 때는 프로그래머가 인스트럭션 레벨 병렬성까지 고려해야 한다.


인스트럭션 레벨 병렬성까지 고려해서 프로그래밍을 하는 예로는 루프 전개를 수행할 때나 **데이터 프리페치**(data prefetch)를 수행하는 경우이다. 루프는 전형적으로 조건문과 실제 실행을 수행하는 두 개의 구문으로 구성되며 조건문과 실제 실행문을 짧은 빈도로 반복하면 조건문이 원인이 되어 인스트럭션 레벨 병렬성이 낮아지기도 한다. 루프 전개를 해두면 이러한 상황을 피할 수도 있다.


데이터 프리페치는 나중에 메모리를 있는 데이터를 이용해 계산을 수행할 것을 미리 알고 있을 경우 사전에 데이터를 메모리에 읽어두는 방법이다. 메모리에 미리 읽어두는 이유는 메모리 읽기 명령은 덧셈이나 뺄셈 같은 명령에 비해 응답속도가 느린 명령이기 때문이다. CPU에 나열된 인스트럭션 레벨 병렬화 기능에 의해 메모리를 읽어 들이는 중에도 다른 덧셈이나 뺄셈 같은 연산 명령을 실행할 수 있기 때문에 메모리 읽기와 연산을 병렬적으로 실행 가능하다.

이 방법은 일반적으로 메모리 프리페치(memory prefetch)라고 부르며 프로그래머가 명시적으로 지정할 수도 있다.


여기서는 파이프라인 처리 개념만 설명한다.



파이프라인 처리에 관한 개요를 설명하기 전에 먼저 CPU 내부에서의 명령 실행 방법을 설명한다. CPU는 일정 간격마다 명렬어 배열을 실행해나간다. 현재 사용되고 있는 대부분의 CPU는 하나의 명령을 몇 개의 단계로 나누어서 실행한다. 예를 들어 명령 실행을 5개로 나누면 다음과 같다.

- **명령 읽기(IF: Instruction Fetch)**

다음에 실행할 명령을 메모리에 읽는다.

- **명령 해석(ID: Instruction Decode)**

읽은 명령을 해석한다.


- **실행(EX: EXecution)**

실제 명령을 실행한다.

- **메모리 엑세스(MEM: MEMory access)**

메모리에 접근한다.(읽기 또는 쓰기)

- 쓰기(WB: Write Back)

레지스터에 연산 결과를 쓴다.


이는 덧셈, 뺄셈, 메모리 읽기와 쓰기 같은 명령이 5단계로 나뉘에 실행되는 것을 나타낸다. 이 분할된 작은 단계를 파이프라인 스테이지(pipeline stage)라 부르면 분할한 수를 파이프라인수라고 부른다. 이 예에서 파이프라인 수는 5다.


**그림 1-8** 각 파이프라인 스테이지의 실행 예



>[!TIP] 
>위 그림에서 클록 1의 버킷 안에 있는 데이터 11011은 2+3을 계산해 `addr[1]`과 a 레지스터 결과를 저장하는 명령을 나타내는 바이너리 열이다.


위 예에서는 2+3 이 실행되고 `addr[1]`과 a 레지스터 ($a)에 결과를 저장하는 명령을 실행하고 있다. 파이프라인 처리는 종종 버킷 릴레이(bucket relay)로 비유되기 때문에 이 첵에서도 버킷 릴레이로 비유한다. 또한 CPU는 클록 사이클 단위로 처리를 진행하므로 시간 축에는 경과 클록 수를 표시한다.


그림에서는 먼저 클록 1에서 IF로 메모리상에서 명령을 읽어 버킷에 명령을 저장한다. 그 뒤 클록 2에서 버킷 안에 있는 명령을 해석한다. 여기에서는 2+3이 실행되어 `addr[1]`과 a 레지스터에 결과를 저장하는 명령이라고 해석한다. 

클록 3에서는 실제로 2+3이 실행되어 버킷을 내용이 실행 결과인 5로 치환된다. 그 뒤 클록 4에서 addr[1]에 결과가 쓰이고, 클록 5에서 a 레지스터에 결과가 쓰인다.


각 클록에선느 처리를 실앻하는 단계 이외에는 아무것도 수행하지 않는다. 버킷 릴레이에서는 여러 버킷을 사용하면 하나의 버킷을 사용해서 물을 나를 때보다 많은 양을 옮길 수 있지만, 파이프라인 처리에서도 버킷 릴레이와 마찬가지로 [그림 1-8]의 비어 있는 단계에서도 동시에 처리를 수행함으로써 여러 인스트럭션을 병렬로 실행한다.


다음 그림은 파이프라인 처리의 작동 원리를 나타낸 것으로 가로축은 경과 시간, 세로축은 명령어 배열이다. 각 클록에서 단계마다 어떤 명령이 실행되는지 나타냈다.

- [그림 1-9]파이프라인 처리 작동 원리



[그림]


위의 그림과 같이 병렬로 명령을 수행할 수 있으며 단위 시간당 실행할 수 있는 명령어 수, 즉 처리량이 향상된다. 그러나 파이프라인 처리를 포함해 인스트럭션 레벨 병렬성으로는 응답속도가 향상되지 않는다는 점에서 유의해야 한다. 또한 그림에서는 8클록으로 4개의 명령을 병렬로 실행하므로 CPI는 $\frac{8}{4}=2$이며 파이프라인 처리를 수행하지 않을 때의 CPI는 5이다. 따라서 이 경우 처리량은 $\frac{5}{2}=2.5$배 향상된다.


단순 계산으로 파이프라인 처리를 수행하면 처리량은 파이프라인 수의 배율만큼 향상된다. 즉, 그림[그림 1-9]예에서는 최대 5배까지 향상된다. 그러나 실제로는 데이터 의존 관계 등으로 인해 이론적인 배율만큼 되지 않는 경우가 대부분이다. 데이터 의존 관계 등의 원인으로 인스트럭션 레벨에서 병렬 실행할 수 없는 상태를 **파이프라인 헤저드**(pipeline hazard)라 부르면 CPU나 컴파일러는 각종 파이프라인 해저드에 대응한 처리를 해야 한다. 이 책에서는 파이프라인 해저드 처리 방법을 설명하지 않으며 파이프라인 해저드의 종류만 소개한다.



- **구조 해저드**(structural hazard)

하드웨어적으로 병렬 수행할 수 없는 명령을 실행했을 때 발생한다. 그림 [그림 1-9] IF와 MEM 모두 메모리 접근을 수행한다고 설명했지만 하드웨어적으로 동시에 메모리 접근을 할 수 없는 경우 IF와 MEM을 병렬적으로 실행할 수 없어 해저드 상태가 된다.


- **데이터 해저드**(data hazard)

데이터 의존 관계가 있을 때 발생한다. 예를 들어 명령 1의 연산 결과를 명령 2에 이어서 이용하는 경우 데이터 해저드 상태가 된다.

- **제어 해저드**(control hazard)

조건 분기가 있을 때 발생한다. 명령 1이 조건 분기고, 그 결과에 따라 명령 2의 실행 여부가 결정되는 경우 제어 해저드 상태가 된다.


