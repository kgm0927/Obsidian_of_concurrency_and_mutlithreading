

### 동시성이 어려운 이유

동시성 코드를 제대로 작성하는 것은 어렵기로 유명하다. 생각대로 동작하게 할려면 일반적으로 반복 작업을 몇 번이나 해야 한다. 심지어 디스크 사용량이 많아지고 시스템에 로그인한 사용자가 늘어나는 등 타이밍이 약간 변경돼, 기존에는 발견되지 않고 한참 동안 소스 코드 속에 숨어 있던 버그가 고개를 쳐드는 일이 있다.

---

### 레이스 컨디션

레이스 컨디션(Race Condition)은 둘 이상의 작업이 올바른 순서로 실행돼야 하지만 프로그램이 그렇게 작성되지 않아서 이 순서가 유지되는 것이 보장하지 않을 때 발생한다.


대부분 이 문제는 하나의 동시 작업이 어떤 변수를 읽으려고 시도하는 동안 또 다른 동시 작업이 특정할 수 없는 시점에 동일 변수 값을 쓰려고 하는 **데이터 레이스**(data race) 인 것으로 밝혀졌다.
``` go
package main

import "fmt"

func main() {

    var data int

    go func() {     // #1
        data++
    }()
    if data == 0 {
        fmt.Printf("the value is %v.\n", data)
    }
}
```

1. Go 에서는 함수를 동시적으로 실행시키기 위해 go 키워드를 사용할 수 있다. 이렇게 하면 고루틴(goroutine)이라는 것이 생성된다. 이 내용은 65페이지의 "고루틴"에서 자세히 설명한다.

여기서 `data++`와 `if data==0` 에서는 모두 변수 데이터에 접근하려고 시도하는데, 이 두 연산이 어떤 순서로 일어나는지는 보장되어 있지 않다. 이 코드를 실행하면 다음 세 가지 결과가 발생할 수 있다.

- 아무것도 출력하지 않는다. 이 경우 3행이 5행보다 먼저 실행된다.
- "the value is 0"이 출력된다. 이 경우 if문의 `data==0`가 `data++`보다 먼저 실행된다.
- "the value is 1"이 출력된다. 이 경우 if문의 `data==0`이 data++보다 먼저 실행했지만, 3행이 6행보다 먼저 실행된다.

몇 줄의 잘못된 코드로 인해 프로그램이 엄청난 변동성이 나타날 수 있다.

==대부분의 데이터 레이스는 개발자가 문제를 순차적으로 생각하기 때문에 일어난다. ==

동시성 코드를 작성할 때는 가능한 한 시나리오를 세심하게 반복해야 한다. ==이 책의 뒷부분에서 다루는 기법 중 일부를 사용하지 않는 한, 소스 코드에서 나열된 순서대로 코드가 실행된다는 보장은 없다.==

때로는 연산들 사이에 많은 시간적 공백이 있다고 상상해보는 것도 도움이 된다. 시간의 단위는 다르지만, 컴퓨터에 있어 상대적인 시간 차는 거의 비슷하기 때문에 이런 공백을 생각하면 꽤 도움이 된다.



사실 일부 개발자는 코드 전체에 걸쳐 sleep을 뿌리는 잘못을 범한다. sleep이 동시성 문제를 해결하는 것처럼 보이기 때문이다.

``` go
package main

import (
    "fmt"
    "time"
)

  

func main() {
    var data int
    go func() {     // #1
        data++
    }()

    time.Sleep(1*time.Second)// 이것은 잘못됐다!
    if data == 0 {
        fmt.Printf("the value is %v.\n", data)
    }

}
```

이 프로그램에서는 세 가지 결과가 모두 발생할 수 있다. 다만 **가능성이 낮을**뿐이다. 고루틴을 호출하고 data 값을 확인하는 사이에 더 오래 sleep 하면 할수록 프로그램은 정확해진다.
==허나 이 확률은 점진적으로 논리적 정확성에 다가가는 것이지 결코 논리적으로 정확한 것은 아니다.==

이 외에도 알고리즘에 비효율적인 요소를 도입하자. 이제 데이터 레이스가 일어나지 않도록 하기 위해 1초 동안 sleep해야 한다. 올바른 도구를 사용했다면, 기다릴 필요가 전혀 없거나 대기 시간이 불과 1마이크로초 정도일 것이다.

중요한 것은, 언제나 논리의 정확성을 추구해야 한다는 것이다. 코드에 sleep을 추가하는 것은 동시성 프로그램을 디버깅하는 편리한 방법이긴 하지만 해결책이 될 수는 없다.


**==레이스 컨디션==** 은 동시성 버그 중 가장 은밀한 유형 중 하나다. 코드가 운영 환경에 투입된 후에도 수년 동안 드러나지 않을 수 있다. 그러다 갑작스럽게 생기는데, 이 경우 코드가 올바르게 작동하는 것처럼 보이지만, 실제로는 연산들이 순서대로 실행될 가능성이 매우 높은 것일 것이다. 즉 언젠가 문제가 터진다는 말이다.


---

### 원자성

무언가가 원자성(atomic)이거나 원자적인 속성을 가지면, 이는 동작하는 컨텍스트 내에서 나누어지거나 중단되지 않는 것을 의미한다.

그러면 원자성이 실제로 의미하는 바는 무엇이며, 동시성 코드로 작업할 때 원자성을 아는 것이 중요한 것은 무엇인가?


여기서 **컨텍스트**(context)를 알아야 한다. 어떤 컨텍스트에서는 원자적인 것이 다른 컨텍스트에서는 아닐 수 있다. 예를 들어, 사용자 프로세스의 컨텍스트 내에서는 원자적인 연산도 운영체제의 컨텍스트에서는 원자적이지 않을 수 있다. 

운영체제의 컨텍스트 네에서 원자적인 연산이 기기의 컨텍스트 내에서 원자적이지 않을 수 있다. 기기의 컨텍스트 내에서 원자적인 연산이 기기의 컨텍스트 내에서 원자적이지 않을 수도 있다. 기기의 컨텍스트 내에서 원자적인 연산도 사용자 애플리케이션 컨텍스트 내에서 원자적이지 않을 수 있다. 

다시말해 연산의 원자성은 현재 정의된 범위(scope)에 따라 달라질 수 있다. 이 사실은 도움이 될 수도 있고, 힘들게 할 수도 있다.

원자성을 생각할 때, 가장 먼저 해야 할 일은 연산이==원자적인 것으로 간주해야 할 컨텍스트 또는 범위를 정하는 것이다.== 다른 것보다 이것이 우선이다.



이제는 **불가분**(indivisible)과 **중단 불가**(uninterruptible)이라는 용어를 살펴보자. 이들 용어는 사용자가 정의한 컨텍스트 내부에서 원자적인 요소가 통째로 발생하며, 해당 컨텍스트 네에서는 해당 요소 외에 어떤 것도 이루어지지 않는다는 것을 의미한다. 예시로 살펴보겠다.

```

i++
```


위의 코드로 원자성의 개념을 쉽게 보여준다. 이 예시가 원자적으로 보일 수도 있지만, 간단히 분석을 통해서 몇 가지 연산으로 구성돼 있음을 알 수 있다.

- i의 값을 가져온다.
- i의 값을 증가시킨다.
- i의 값을 저장한다.


이런 각 연산은 원자적이지만, 세 연산의 조합은 컨텍스트에 따라 원자적이지 않을 수 있다. 바 원자적 연산을 조합한다고 해서 반드시 더 큰 원자적 연산이 생성되는 것은 아니라는 점이다.

연산을 원자적으로 만드는 것은 사용자가 어떤 컨텍스트에서 원자성을 얻고자 하는지에 달려 있다. 동시에 수행되는 프로세스들이 없는 프로그램의 컨텍스트라면, 이 코드는 해당 컨텍스트 내에서 원자적이다. i 값을 다른 고루틴들에게 노출하지 않은 고루틴의 컨텍스트인 경우에도 이 코드는 원자적이다.


그렇다면  왜 원자성에 대해 신경을 써야 할까? 무언가각 원자적이라면 암묵적으로 동시에 실행되는 컨텍스트들 내에서 안전하다는 것을 의미하기 때문에 원자성은 중요하다. 원자성은 논리적으로 올바른 프로그램을 작성할 때 필요한 요소이며, 나중에 살펴보겠지만 동시성 프로그램들을 최적화하는 방법이기도 하다.


함수, 메서드, 프로그램은 고사하고 대부분의 구분조차 원자적 요소가 아니다. 원자성이 논리적으로 올바른 프로그램을 작성하는 열쇠라면, 그리고 대부분의 구문을 원자적이지 않다면 이 두 사실을 어떻게 조화시켜야 할까? 간단히 말하면 다양한 기법을 사용해 원자성을 강제할 수 있다. 그 후부터는 코드의 어느 영역이 원자적이어야 하는지, 어느 정도의 세분화가 필요한지 결정하는 것이 기술이다. 


----

### 메모리 접근 동기화

다음과 같은 데이터 레이스 상황을 생각해보면, 동시에 실행되는 두 프로세스가 동일한 메모리 영역에 접하려고 시도하고 있으며, 각 프로세스가 메모리에 접근하는 방식은 원자적이지 않다고 가정한다. 앞에서 살펴본 레이스 예제를 조금만 수정하면 된다.


``` go
package main

import (
    "fmt"
)
func main() {

    var data int
    go func() {
        data++
    }()
    if data == 0 {

        fmt.Println("the value is 0.")

    } else {
        fmt.Println("the value is %v .\n", data)
    }
}
```

data 값에 상관없이 항상 무언가가 출력되도록 하기 위해 else 절을 추가했다. 앞서 말한 대로 데이터 레이스가 존재하며, 이 프로그램의 출력은 완전하게 비결정적이라는 사실을 기억하라. 실은 프로그램에서 공유 리소스에 독점적으로 접근해야 하는 영역(section)을 칭하는 이름이 있다. 이를 **임계 영역**(critical section)이라고 한다. 이 예제에서는 세 가지 임계영역이 있다.

- data 변수를 증가시키는 gorountine
- data 값이 0인지 확인하는 if 구문
- 출력할 data의 값을 가져오는 fmt.Printf 구문


프로그램에서 임계 영역을 보호하는 다양한 방법이 존재하며, 그 중 한 가지 방법이 임계 영역 간의 메모리 접근을 동기화하는 것이다. 다음 예시를 보겠다.


다음 Go 코드는 관용적으로 사용되는 것이 아니며, 이런 식으로 데이터 레이스 문제를 해결하는 것도 권하지 않는다. 하지만 이 방식은 메모리 접근 동기화를 매우 간단하게 보여준다. 이러한 호출을 통해 메모리에 대한 접근을 동기화한다는 개념에 중점을 두도록 하자.

``` go
package main
import (
    "fmt"
    "sync"
)

  

func main() {
    var memoryAccess sync.Mutex // #1
    var value int
    go func() {
        memoryAccess.Lock() // #2
        value++
        memoryAccess.Unlock() // #3
    }()
    memoryAccess.Lock()

    if value == 0 {
        fmt.Printf("the value is %v.\n", value)
    } else {
        fmt.Printf("the value is %v.\n", value)
    }
    memoryAccess.Unlock()
}

```

1. data 변수의 메모리에 대한 접근을 동기화(synchronize)할 수 있게 해 주는 변수를 추가한다. sync.Mutex타입에 대해서는 78페이지의 "sync 패키지"에서 자세히 설명한다.
2. 별도로 선언할 때까지 고루틴이 이 메모리에서 독점적으로 접근해야 한다고 선언한다.
3. 고루틴이 이 메모리에 대한 접근을 끝냈다고 선언한다.
4. 다시 한번 다음 조건문이 data 변수의 메모리에 독점적으로 접근해야 한다고 선언한다.
5. 다시 한번 이 메모리에 대한 접근이 끝났다고 선언한다.


이 예제에서는 개발자가 따를 수 있는 규칙(convention)을 만들었다. 개발자는 data 변수의 메모리에 접근하려고 할 때마다 Lock을 호출해야 하며,완료되면 Unlock을 호출해야 한다. 완료되면 Unlock을 호출해야 한다. 이 두 구문 사이에 코드는 data에 독점적으로 접근할 수 있는 것으로 간주된다. 메모리에 대한 접근을 성공적으로 동기화한 것이다.

또한 개발자가 이 규칙을 따르지 않는다면 독점적인 접근이 보장되지 않는다는 점에 유의하자. 이 개념은 "제한"이라는 개념에서 다시 볼 수 있을 것이다.

데이터 레이스를 해결하는 동안, 실제로 레이스 컨디션을 해결하지는 못했다는 사실을 알아챘을지도 모른다! ==이 프로그램의 연산 순서는 여전히 비결정적이다.== 단지 비결정적인 부분의 범위를 조금 좁혔을 뿐이다. 이 예에서 고루틴이 먼저 실행될 수도 있고, if와 else 블록 모두가 실행될 수도 있다. 이 프로그램에게 주어진 실행 환경에서 어느 것이 먼저 일어날 지 전혀 알지 못한다. 나중에 이 문제를 올바르게 해결할 도구를 살펴볼 것이다.


겉보기는 간단해 보이는데, 임계 영역을 발견하면 메모리에 대한 접근을 동기화시키기 위한 포인트를 추가한다. 쉽지 않은가?

메모리에 대한 접근을 동기화해 몇 가지 문제를 해결할 수는 있지만, 방금 본 것처럼 이것이 데이터 레이스나 논리적인 정확성을 자동으로 해결하지는 못한다. 또한 이 방식이 유지 관리 및 성능 문제를 일으킬 수 있다.

앞에서 특정 메모리에 독점적으로 접근해야 한다고 선언하기 위한 규칙을 만들었다고 말했다. 규칙은 훌륭하지만 쉽게 무시할 수 있다. 사업상 요구사항이 때로는 신중함보다 중요시되는 소프트웨어 엔지니어링의 경우에는 특히 그렇다.
이러한 방식으로 메모리에 대한 접근을 동기화함으로써, 다른 모든 개발자가 현재에도, 앞으로도 동일한 규칙을 따를 것이라고 기대할 것이다. 그건 꽤 어려운 주문이다. 이부분은 성공적으로 할 수 있게 뒷부분에서 배워 볼 것이다.

이러한 방식으로 메모리에 대한 접근을 동기화하는 것은 성능에도 영향을 미친다. Lock 호출이 프로그램을 느려지게 만들 수 있다. 이러한 연산들 중 하나를 수행할 때마다 프로그램은 일정 시간 멈춘다. 여기서 두 가지 의문이 있다.

- 임계 영역에 반복적으로 들어갔다 나오는가?
- 임계 영역은 어느 정도 크기여야 하는가?


프로그램의 컨텍스트에서 이 두가지 질문에 정답은 없다.


메모리 접근 동기화 기법 및 다른 동시성 문제 모델링 기법에는 몇 가지 공통된 문제점이 있다. 다음 절에서 이에 대해 설명한다.




#### 데드락, 라이브락, 기아 상태

이런 문제들을 성공적으로 다루더라도 데드락(deadlock), 라이브락(livelock), 기아 상태(starvation) 같은 또 다른 문제가 발생한다. 이들 문제는 프로그램이 언제나 유용하게 동작하도록 하는 것과 관련이 있다.


#### 데드락

프로그램이 데드락 상태에 빠지면, 해당 프로그램에서 동시에 실행 중인 모든 프로세스는 자신이 아닌 다른 프로세스가 끝나기만을 기다린다. ==데드락 상태가 되면 외부 개입이 없이는 결코 프로그램을 복구할 수 없다.==

Go 런타임이 일부 데드락(모든 고루틴이 대기하고 있거나 "잠들어 있는" 상황)을 탐지하는 자신의 역할을 하겠지만, 그렇다고 데드락을 방지하는 데 많은 도움이 되지 않는다.


다음 예제를 살펴보도록 하겠다.


``` go
package main
import (
    "fmt"
    "sync"
    "time"
)

  

type value struct {
    mu    sync.Mutex
    value int
}

  

func main() {
   var wg sync.WaitGroup

    printSum := func(v1, v2 *value) {

        defer wg.Done()
        v1.mu.Lock()         // #1
        defer v1.mu.Unlock() // #2

        time.Sleep(2 * time.Second) // #3
        v2.mu.Lock()
        defer v2.mu.Unlock()
        fmt.Printf("sum=%v\n", v1.value+v2.value)
    }
    var a, b value
    wg.Add(2)
    go printSum(&a, &b)
    go printSum(&b, &a)
    wg.Wait()
  

}
```


1. 여기서는 입력값(v1)을 위해 임계 영역에 진입하려고 시도한다.
2. printSum 함수가 리턴되기 전에 임계 영역을 벗어나도록 하기 위해 defer 문을 사용하고 있다.
3. 여기서 일정 시간 동안 sleep 하면서 임의의 작업을 수행하는 것처럼 시뮬레이션 한다(그리고 데드락을 유발한다).

이 코드를 실행하려고 한다면 다음과 같은 메시지가 나온다.

```
fatal error: all groutines are asleep -deadlock!
```

주의 깊게 살펴보면 이 코드에서 타이밍 문제가 발생한다는 것이 보인다. 다음은 진행 상황을 시각적으로 표현한 것이다. 박스는 함수 가로선은 함수에 대한 호출, 세로 막대는 위쪽에 있는 함수의 수명을 의미한다.

[그림]





본질적으로 함께 동작할 수 없는 두 개의 기어를 만들었다. 첫 번째 printSum 호출은 a를 잠근 다음 b를 잠그려고 시도했지만, 그 사이에 두 번째 printSum 호출이 b를 잠그고 a를 잠그려고 시도했다. 두 고루틴은 무한히 서로를 기다린다.



시각적으로 보면 데드락이 나타난 이유는 명확하지만, 보다 엄격히 정의해보면 도움이 될 것이다. 데드락이 발생하기 위해서는 몇 가지 조건이 필요한데, 1971년 에드가 코프먼(Edgar Coffman)은 논문에서 이러한 조건을 나열했다. 코프먼 조건으로 알려진 이 조건들은 데드락을 탐지, 예방 및 교정하는 것을 돕는 기법들의 기반이 된다.

==코프먼 조건==은 다음과 같다.


- 상호 배제(Mutual Exclusion)

동시에 실행되는 프로세스가 어떤 임의의 시점에 하나의 **리소스에 대한 배타적 권리**를 보유한다.

- 대기 조건(Wait for condition)

동시에 실행되는 프로세스는 하나의 리소스를 보유하고 있는 동시에 또 다른 추가 리소스를 기다리고 있다.

- 비선점(No Preemption)

동시에 실행되는 프로세스 중 하나를 보유하고 있는 리소스는 해당 프로세스에 의해서만 사용 해제(release)될 수 있으므로 이 조건도 만족한다.

- 순환 대기(Circular Wait)

동시에 실행되는 프로세스 중 하나가(P1)가 다른 동시 프로세스(P2)로 이어지는 체인에서 기다려야 하며, P2는 최종적으로 P1을 기다려야 하는데, 이 마지막 조건 역시 충족된다.


[그림]

부자연스러운 프로그램을 검토하고, 네 가지 조건을 모두 충족하는지 확인해보자.

1. printSum 함수는 a와 b모두에 대한 배타적인 권한을 필요로 하므로 이 조건을 충족한다.
2. printSum는 a 또는 b 중에 하나를 보유한 상태에서 다른 하나를 기다리고 있으므로 이 조건을 충족한다.
3. 다른 프로세스가 고루틴이 보유한 자원을 선점할 수 있는 어떤 여지도 제공하지 않는다.
4. printSum에 대한 첫 번째 호출은 두 번째 호출을 기다리고 있으며, 그 반대의 경우도 마찬가지다.

확실히 데드락임으로 알 수 있다.


이 조건들은 데드락을 방지할 수 있게 해 주기도 하며, 하나라도 이 조건이 참이 아니라면 데드락을 막을 수 있다. 

하지만 이들 조건을 추론하는 것은 어려울 수 있으므로 데드락을 예방하는 것은 쉽지 않다. 어째서 코드 조각(code snippet)이 데드락에 빠졌는지 궁금해하는 개발자들의 질문을 자주 들을 수 있다. 

원인이 분명해 보이지만 많은 경우 원인을 파악하기 위해 오랜 시간이 필요하다. 이는 "동시실행 안전성 판단"에서 이야기할 것이다.


---

### 라이브락


==프로그램들이 활동적으로 동시에 연산을 수행하고는 있지만, 이 연산들이 실제로 프로그램의 상태를 진행시키는데 아무런 영향을 주지 못하는 의미 없는 연산상태를 의미한다.==


예를 들어 두 사람이 서로가 같은 길에서 마주보는 방향으로 걸어오고 있다고 생각해 보자. 그러면 한명은 길을 비켜 주어야겠지만, 양쪽 다 길을 비켜준다고 생각해 볼 때, 두 사람 모두 길을 건너지 못할 것이다. 이 상태가 라이브락이다.


이 시나리오를 설명하는데 도움이 되는 코드를 작성해보겠다. 먼저 예제를 단순히 만들어주는 몇 가지 도우미 함수(helper function)를 설정한다. 실제로 동작하는 예제를 만들기 위해 이 코드에는 아직 다루지 않은 몇 가지 주제를 사용했다. 

sync 패키지에는 그 중 하나인데, 지금은 다루지 않고, 대신 하이라이트된 부분을 이해하기 위해 코드의 호출을 따라가보고, 이 예제의 핵심을 포함하는 두 번째 코드 블록에 주의를 기울일 것을 권한다.

``` go
cadence := sync.NewCond(&sync.Mutex{})
    go func() {
        for range time.Tick(1 * time.Millisecond) {
            cadence.Broadcast()
        }
    }()

    takeStep := func() {
        cadence.L.Lock()
        cadence.Wait()
        cadence.L.Unlock()
    }

  

    tryDir := func(dirName string, dir *int32, out *bytes.Buffer) bool { // #1
        fmt.Fprintf(out, "%v", dirName)

		atomic.AddInt32(dir, 1)  // #2
	    takeStep()   // #3
        if atomic.LoadInt32(dir) == 1 {
            fmt.Fprint(out, ". Success!")
            return true
        }
        takeStep()
        atomic.AddInt32(dir, -1)  // #4
        return false

    }
    var left, right int32
    tryLeft := func(out *bytes.Buffer) bool { return tryDir(" left", &left, out) }

    tryRight := func(out *bytes.Buffer) bool { return tryDir(" right", &right, out) }
```

1. tryDir은 어떤 사람이 특정 방향으로 움직이게 시도할 수 있도록 해주고, 그 시도가 성공했는지 아닌지 리턴하는 함수이다. 각 방향은 그 방향으로 움직이고자 하는 사람들의 수를 표시한다.
2. 먼지, 인자로 주어진 방향을 1씩 증가시킴으로써 그 방향으로 움직이겠다는 의사를 표현한다. atomic 패키지에 대해서는 3장에서 자세하게 다룬다. 현재로서는 이 패키지의 연산들이 원자적이라는 사실만 알면 된다. 라이브락을 보여주기 위한 예제에서는 각자가 동일한 속도, 즉 보조를 맞추어 움직여야 한다.
3. takeStep은 모든 참가자가 일정한 보조로 움직이는 것을 시뮬레이션한다.
4. 이 시점에서 이 사람은 이 방향으로 갈 수가 없다는 것을 깨닫고 포기한다. 그 방향을 1만큼 줄이는 것으로 이를 표현한다.

``` go
    walk := func(walking *sync.WaitGroup, name string) {
        var out bytes.Buffer
        defer func() {
            fmt.Println(out.String())
        }()
        defer walking.Done()

        fmt.Fprintf(&out, "%v is trying to scoot:", name)

  

        for i := 0; i < 5; i++ { // #1
            if tryLeft(&out) || tryRight(&out) { //#2
                return
            }
        }
        fmt.Fprintf(&out, "\n%v tosses her hands up in exasperation!", name)
    }

  

    var peopleInHallway sync.WaitGroup // #3
    peopleInHallway.Add(2)
    go walk(&peopleInHallway, "Alice")
    go walk(&peopleInHallway, "Barbara")
    peopleInHallway.Wait()
```

1. 프로그램이 종료될 수 있도록 인위적인 제한을 두었다. 라이브락이 있는 프로그램은 이러한 제한이 없기 때문에 문제가 된다.
2. 먼저 한 사람이 왼쪽으로 움직이려고 시도하고, 실패하면 오른쪽으로 움직이려 한다.
3. 이 변수는 두 사람이 서로를 지나쳐 가거나 혹은 포기할 때까지 프로그램이 기다릴 수 있게 하는 방법을 제공한다.

결과는 이러하다.

``` shell
PS C:\Users\kgm09\goproject\src> go run main.go
Barbara is trying to scoot: left right left right left right left right left right
Barbara tosses her hands up in exasperation!
Alice is trying to scoot: left right left right left right left right left right
Alice tosses her hands up in exasperation!
```

Alice와 Barbara가 마침내 포기하기 전까지 서로의 길을 막아서는 것을 볼 수 있다.

이 예제는 동시에 실행되는 두 개 이상의 프로세스가 아무런 조정 없이 데드락을 방지하려고 시도하는 상황을 보여준다. 이는 라이브락이 작성되는 매우 일반적인 이유이기도 하다. 복도에 있는 사람들이 그들 중 단 한 사람만 움직이자고 서로 합의했다면, 한 사람은 멈춰서고 다른 한 사람은 반대편으로 이동할 것이며, 그들은 계속 걸어갈 수 있었을 것이다.

프로그램이 마치 동작하는 것처럼 보이기 때문에 라이브락은 데드락보다 알아차리기 어렵다. 라이브락에 빠진 프로그램이 기기에서 실행되고 있을 때 이 프로그램이 뭔가를 하고 있는지 알아보기 위해 CPU 사용률을 조사해본다면, 아마도 프로그램이 동작하고 있다고 판단하게 될 것이다. 라이브락에 따라서는 작업 중이라고 생각하게 할 만한 다른 신호들을 보낼 수도 있다. 그럼에도 불구하고, 프로그램이 복도를 왔다갔다 하는 영원한 게임을 하고 있을 것이다.


---

### 기아 상태

(Starvation)
어떤 프로세스가 작업을 수행하는데 필요한 모든 리소스를 얻을 수 없는 상황을 의미한다.


앞에서 라이브락에 대해 언급했다. 고루틴이 굶주려 있던 자원은 공유 잠금(Shared lock)이었다. 라이브락에서는 동시에 실행되는 모든 프로세스가 동일하게 리소스를 얻지 못하고 어떠한 작업도 완료되지 않기 때문에, 라이브락을 기아 상태와 별도로 논의하는 것이 당연하다. 일반적으로 기아 상태란, 다른 동시 프로세스 혹은 프로세스들이 가능한 효율적으로 작업을 수행하는 것을 부당하게 방해하거나, 작업을 전혀 수행하지 못하게 만드는 욕심 많은 동시 프로세스가 하나 이상 존재한다는 것을 암시한다.

``` go
package main

import (
    "fmt"
    "sync"
    "time"
)


type value struct {
    mu    sync.Mutex
    value int
}

  

func main() {

    var wg sync.WaitGroup
    var sharedLock sync.Mutex
    const runtime = 1 * time.Second  

    greedyWorker := func() {
        defer wg.Done()
    }

    var count int
    for begin := time.Now(); time.Since(begin) <= runtime; {
        sharedLock.Lock()
        time.Sleep(3 * time.Nanosecond)
        sharedLock.Unlock()
        count++
    }

    fmt.Printf("Greedy worker was able to execute %v work loops\n", count)

  

    politeWorker := func() {
        defer wg.Done()
        var count int
        for begin := time.Now(); time.Since(begin) <= runtime; {
            sharedLock.Lock()
            time.Sleep(1 * time.Nanosecond)
            sharedLock.Unlock()
            sharedLock.Lock()
            time.Sleep(1 * time.Nanosecond)
            sharedLock.Unlock()

  

            sharedLock.Lock()
            time.Sleep(1 * time.Nanosecond)
            sharedLock.Unlock()
            count++
        }

        fmt.Printf("Polite worker wsa able to execute %v work loops. \n", count)

    }

  

    wg.Add(2)
    go greedyWorker()
    go politeWorker()
    wg.Wait()

}
```


결과

``` shell
PS C:\Users\kgm09\goproject\src\Concurrency> go run main.go
Greedy worker was able to execute 76 work loops
Polite worker wsa able to execute 27 work loops.
PS C:\Users\kgm09\goproject\src\Concurrency> go run main.go
Greedy worker was able to execute 84 work loops
Polite worker wsa able to execute 24 work loops.
PS C:\Users\kgm09\goproject\src\Concurrency> go run main.go
Greedy worker was able to execute 73 work loops
Polite worker wsa able to execute 24 work loops.
```

욕심 많은 작업자는 탐욕스럽게도 자신의 전체 작업 루프 동안 공유 잠금을 가지고 있는 반면, 예의 바른 작업자는 자신이 필요할 때만 잠금을 시도했다. 두 작업자 모두 동일한 양의 시뮬레이션 작업을 수행하지만(3나노초 동안의 sleep), 앞에서 볼 수 있듯이 같은 시간 동안 욕심 많은 작업자는 거의 2~배 정도의 작업량을 얻었다.


그렇다고 욕심 많은 작업자의 알고리즘이 더 효율적이라고 결론짓거나 또는 실제로는 느리지 않은 Lock 및 Unlock 함수에 대한 호출로 인해 속도가 느려졌다고 결론지어서는 안 된다. ==두 작업자가 같은 크기의 임계 영역을 가지고 있다면, 욕심 많은 작업자는 임계 영역을 벗어난 후에도 불필요하게 공유 잠금을 보유함으로써 기아 상태를 일으키고 있다.== 그리고 이로 인해 예의 바른 작업자의 고류틴이 효율적으로 작업을 수행하는 것을 방해받고 있다는 것이 제대로된 판단이다.

여기서 기아 상태를 확인하기 위한 기법인 계측(metric)에 주목하자. 기아 상태는 기록 및 표본 계측(sampling metric)을 뒷받침하는 훌륭한 논거이다. 계측은 기아 상태를 감지하고 해결할 수 있는 방법 중 하나로, 작업이 완료되었을 때 로깅을 통해 작업 속도가 예상만큼 높은지 판단하는 것이다.


> [!균형 잡기]
> 앞의 코드 예제는 메모리 접근 동기화의 성능 파급 효과를 보여주는 예이기도 하다. 동기화된 메모리 접근에는 비용이 많이 들기 때문에 임계 영역 너머까지 잠금을 확장하는 것이 유리할 수 있다. 반면에 이렇게 하면 앞서 배웠듯이 다른 동시 프로세스를 기아 상태에 빠뜨릴 위험이 있다. 
> 메모리 접근 동기화를 사용하는 경우, 성능을 위해 큰 범위에서 동기화할지 혹은 공정성을 위해 세분화된 범위의 동기화를 수행할지에 대한 균형점을 찾아야 할 것이다. 애플리케이션의 성능을 조정해야 할 때가 되면 우선 임계 영역에서만 메모리 접근을 동기화하도록 제한할 것을 강력 추천한다.
> 동기화가 성능에 문제를 일으키는 경우 언제든 범위를 확장할 수 있다. 하지만 반대 방향으로 이동하는 것은 훨씬 어렵다.

기아 상태로 인해 프로그램이 비효율적이거나 잘못된 방식으로 작동할 수 있다. 앞에의 예제는 비효율성을 보여준다. ==그러나 동시에 실행 중인 다른 프로세스의 작업 수행을 완전히 막을 정도로 욕심이 많은 동시 프로세스가 있다면 더 큰 문제가 발생하게 된다. 기사 상태가 Go 프로세스의 외부에서 초래되는 경우도 고려해야 한다.== 기아 상태는 CPU, 메모리, 파일 핸들, 데이터베이스 연결에도 적용될 수 있음을 염두해야 한다. 
공유해야 하는 리소스는 모두 기아 상태에 빠질 수 있는 후보이다.




#### 동시실행 안전성 판단


마침내 동시성 문제를 개발하는데 있어 가장 어려운 문제와 마주했다. 이 문제는 나머지의 문제들의 근간이 된다. 바로 사람이다.

코드의 모든 행(line) 이면에는 적어도 한 명의 사람이 있다. 앞서 배웠듯이, 동시에 실행되는 코드가 어려운 이유는 무수히 많다. 개발자가 새로운 기능을 도입하거나 프로그램의 버그를 수정하는 과정에서 이러한 모든 문제에 대해 언쟁을 벌일 생각이라면 제대로된 결정을 내리는 것이 정말 어려울 수 있다.


아무것도 없는 상태에서 시작해 문제 공간을 모델링할 합리적인 방법을 구축해야 하는데, 동시성까지 개입된다면 알맞은 수준의 추상화 지점을 찾는 것이 어려울 수 있다. 호출자들에게 동시성을 어떤 식으로 노출할 것인가? 쉽게 사용하고 수정할 수 있는 솔루션을 만들기 위해 어떤 기법을 사용하는가? 이 문제에서 적절한 동시성 수준은 무엇인가? 이는 예술적인 기교의 영역이다.

다음 함수 시그니처(function signature)를 보자.

``` go

// CalculatePi 함수는 시작(begin)과 끝(end) 사이의
// 파이(Pi) 자릿수를 계산한다.

func CalculatePi(begin,end int64,pi* Pi)

```

큰 정밀도로 파이를 계산하는 것은 동시에 수행할 수 있는 작업이지만, 이 예제는 많은 질문을 유발한다.

- 이 함수를 사용해 어떻게 동시에 수행할 것인가?
- 이 함수를 동시에 여러 번 호출하는 것은 누가 담당하는가?
- 함수의 모든 인스턴스가 내가 전달한 주소를 가진 Pi 인스턴스에서 직접 동작할 것이다. 해당 메모리에 대한 접근을 동기화할 책임이 나에게 있는가, 아니면 Pi 타입이 이를 처리하는가?

하나의 함수에서 이러한 모든 질문이 발생한다. 적당한 크기의 프로그램을 상상해보면 동시성이 초래할 수 있는 복잡성을 이해할 수 있다. 이 시점에서 주석(comment)이 놀라운 역할을 할 수 있다. CalculatePi가 이전과는 다르게 다음과 같은 식으로 작성되어 있다고 생각해 보자.

``` go

// CalculatePi 함수는 시작(begin)과 끝(end) 사이의
// 파이(Pi) 자릿수를 계산한다.
//
// 내부적으로, CalCulatePi는 CalCulatePi를 재귀(recursively)호출하는
// FLOOR((end-begin)/2)개의 동시 프로세스를 생성할 것이다.
// 'pi 변수에 쓰는 작업에 대한 동기화'는 Pi 구조체 내부에서 처리한다.


func CalCulatePi(begin,end int64,pi *Pi)

```


이제는 함수를 평범하게 호출할 수 있으며, 동시성이나 동기화를 걱정하지 않아도 된다. 이때 이 주석이 다음과 같은 측면을 포함한다는 점에 주목하자.

- 누가 동시성을 책임지는가?
- 문제 공간은 동시성 기본 요소에 어떻게 매핑되는가?
- 동기화는 누가 담당하는가?

동시성이 관련돼 있는 문제 공간에서 함수, 메서드 및 변수를 외부로 노출할 때는 동료와 미래의 자신을 위해 호의를 베풀도록 하자. 지나치나 싶을 정도로 자세하게 주석을 달고 세 가지 측면을 모두 다루려고 노력해야 한다.

또한 이 함수의 모호함은 모델링을 잘못한 것에서 비롯됐다고 생각하자. 아마 함수적인 접근법(functional approach)을 취하고 함수에 부작용(side effect)이 없도록 예방해야 했을 것이다.

``` go

func CalculatePi (begin,end int64)[]uint

```

이 함수의 시그니처만으로도 동기화에 대한 모든 질문이 해결됐지만, 여전히 동시성이 사용됐는지에 대한 의문은 남는다. 다시 한번 함수 시그니처를 변경해 어떤 일이 일어나는지 알려주는 신호를 보내도록 한다.

``` go
func CalculatePi(begin,end int64)<-chan uint
```

여기서 채널(channel)이라는 것을 처음으로 사용하는 것을 볼 수 있다. "채널"은 나중에 설명하겠지만, 이것은 CalculatePi가 적어도 하나의 고루틴을 가지게 될 것이므로, 별도의 고루틴을 생성해서 이 함수를 성가시게 해서는 안 된다는 것을 시사한다.


이런 수정 작업은 성능에 영향을 미치므로, 이제 다시 성능과 명확성 사이의 균형 문제로 돌아간다. 가능한 한 이 코드로 작업하는 사람들이 제대로 작업할 수 있기를 원하기 때문에 명확성이 중요하며, 성능 역시 여러 가지 이유로 중요하다. 이 두 가지가 상호 베타적이진 않지만 둘은 섞는 것이 어렵다.

만약 이것을 팀 프로젝트로 확장할 때, 이는 문제가 생길 수 잇다.

Go 언어는 가독성과 단순함을 선호한다. 이 언어에서 권장하는 동시성 코드 모델링 방식은 **정확성**(correctness), **합성 가능성**(composablility) 및 **확장성**(scalability)을 높여준다. 


---

### 복잡성 속의 단순함

동시성은 컴퓨터 과학 분야에서 확실히 어려운 영역이지만, 좌절하지 않았으면 좋겠다. 2장에서는 이러한 진전이 어떻게 이루어졌는지 알아보겠다. 이때 Go 동시성 기본 요소가 실제로 문제 영역을 모델링하고, 알고리즘을 보다 명확하게 표현할 수 있다는 점을 살펴보는데 약간의 시간을 할애한다.

Go의 런타임은 어려운 작업 대부분을 처리하면, Go가 제공하는 동시성 세부 사항의 기반을 제공한다. 이것은 6장에서 논의해야 한다.

대기 시간이 짧은 Go의 가비지 컬렉터(garbage collecter)를 살펴본다. Go의 가비지 컬렉터는 성능이 매우 뛰어나서 그 세부적인 동작 방식까지 신경써야 하는 경우는 크게 줄었다. Go 1.8 이후, 가비지 컬렉션으로 인한 프로그램의 일시 정지는 일반적으로 10~100마이크로초다.

이 점이 시사하는 바는 무엇일까? 메모리 관리는 컴퓨터 과학에서 또 다른 문제점이 될 수 있으며, 동시성과 결합하면 올바른 코드를 작성하는 것이 매우 어려워질 수 있다. 10 마이크로초 정도의 일시 정지에 대해 걱정할 필요가 없는 대다수 개발자라면, ==Go를 사용하면 프로그램에서 동시성을 사용할 때 메모리를 관리하지 않고 동시 프로세스들만 신경 쓰면 되므로 동시성을 훨씬 쉽게 쓸 수 있다.==
또한 Go의 런타임은 동시 연산을 운영체제의 **스레드로 다중화**(multiplexing)하는 일도 자동으로 처리한다. '고루틴'에 대해서 설명을 들을 때, 그 정확한 의미를 알 수 있을 것이다. 왜 이 작업이 유용한가 하면 스레드를 시작하고 관리하여 프로그램의 논리를 사용 가능한 스레드에 균등하게 매핑하는 세부 사항을 처리하는 대신 동시성 문제를 **동시성 생성자**(concurrent construct)에 직접 매핑할 수 있다.

예를 들어, 웹 서버를 작성하는데 수락된 모든 연결이 다른 모든 연결과 동시에 처리되도록 하고 싶다고 가정하자. 일부 언어에서는 웹서버가 연결 수락을 시작하기 전에 일반적으로 스레드 풀(pool)이라고 하는 스레드 컬렉션을 만든 다음, 들어오는 연결을 스레드로 매핑해야 한다. 그런==다름, 생성한 각 스레드 내에서 해당 스레드의 모든 연결을 돌면서 그들이 모두 CPU 시간을 할당 받을 수 있도록 해야 한다.== ==게다가 다른 연결과 공평하게 공유할 수 있도록 연결을 처리하는 논리를 중간에 멈출 수 있도록 작성해야 한다.==

이와는 달리 Go에서는 함수를 작성한 다음, 이를 호출할 때 앞에 go 키워드를 추가하면 된다. 그러면 런타임에 앞서 논의한 모든 것을 자동으로 처리한다! 프로그램을 설계하는 과정을 진행할 대 어느 모델이 동시성에 도달할 가능성이 크다고 생각하는가? 어느 것이 정확할 가능성이 높다고 생각하는가?

또한 Go의 동시성 기본 요소는 더 큰 문제를 쉽게 구성할 수 있게 해 준다. Go의 채널 기본 요소는 동시에 실행되는 프로세스 사이에서 구성 가능하면서 동시 실행에 안전한 방식(concurrent-safe)으로 통신할 수 있는 방법을 제공한다.

이런 기능들의 작동 원리를 대충 언급하고 넘어갔지만, Go가 어떤 식으로 프로그램에서 동시성을 사용해 명확하고 효율적인 방법으로 문제를 해결해주는지 조금이라도 알게 됐으면 한다. 