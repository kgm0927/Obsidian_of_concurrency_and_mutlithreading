
Go 언어로 작업할 때는 언어 자체가 동시성을 매우 쉽게 만들어 주기 때문에 이 동시성을 제대로 활용하는 것이 중요하다! Go의 런타임이 모든 것을 하나로 엮는 방법을 이해해야 하는 경우는 거의 없었다. 그러나 여전히 이 정보가 유용한 경우가 있으며, 2장에서 논의했던 내용들 역시 Go의 런타임 덕분에 가능한 것이기 때문에 런타임의 동작 방식을 잠시 살펴볼 가치가 있다. 또한 런타임은 재미있다는 부가적인 이점을 가지고 있다.

Go 런타임이 하는 모든 일 중 고루틴을 생성하고 관리하는 일이 아마 당신과 당신의 소프트웨어에 유익할 것이다. Go를 탄생시킨 회사인 구글은 전부터 컴퓨터 과학 이론과 백서를 업무에 활용해왔기 때문에, Go에 학계의 여러 아이디어가 포함돼 있다는 것은 놀라운 일이 아니다. 놀라운 것은 개별 고루틴의 뒤에 존재하는 정교함이다. Go는 프로그램의 성능을 향상시키는 몇 가지 강력한 아이디어를 휼륭하게 수행했을 뿐만 아니라, 이런 세부 사항을 추상화하고 개발자가 작업할 수 있는 매우 간단한 외관을 제공하는 데도 성공했다.

---

### 작업 가로채기

57 페이지의 "[[코드 모델링, 순차적인 프로세스 간의 통신#동시성을 지원하는 언어의 장점|동시성을 지원하는 언어의 장점]]"과 65페이지의 "[[Go의 동시성 구성 요소#고루틴|고루틴]]"에서 설명했듯이, Go는 OS 스레드에 다중화하는 방식으로 고루틴을 다룬다. 이를 위해 사용하는 알고리즘을 작업 가로채기(work stealing) 전략이라고 한다. 무슨 뜻일까?

먼저 공정한 스케줄링이라고 하는, 여러 개의 프로세서에서 작업을 공유하기 위한 단순한 전략을 살펴보겠다. 모든 프로세스가 동등하게 활용되도록 하기 위해, 사용 가능한 모든 프로세서 간에 부하에 균등하게 분산시킬 수 있다. 작업을 수행할 n개의 프로세서와 x개의 작업이 있다고 가정해보자. 공정한 스케줄링 전략에서 각 프로세서는 x/n 개의 작업을 얻는다.


[그림]


불행하게도 이 접근 방시에는 문제가 몇 가지 있다. 65페이지의 "고루틴"을 기억하는지 모르겠지만, Go는 fork-join 모델을 사용해 동시성을 모델링한다. fork-join 패러다임에서는 작업들이 서로 의존적일 가능성이 높으며, 단순하게 프로세서별로 분할하면 프로세서 중 하나가 제대로 활용하지 않을 수 있다. ==이뿐만 아니라, 동일한 데이터를 필요로 하는 작업들이 서로 다른 프로세서에서 스케줄링돼 **캐시의 지역성**(cache locality)이 나빠질 수 있다. 예제를 통해 그 이유를 살펴보자.==

앞에서 설명한 공정한 스케줄링 전략에 따라 프로세서에 작업이 분산되는 간단한 프로그램을 생각해보자. 작업 2가 완료될 때까지 더 오래 걸린다면 어떻게 될까?

| 시간    | P1   | P2  |
| ----- | ---- | --- |
|       | T1   | T2  |
| n+a   | T3   | T2  |
| n+a+b | (유휴) | T4  |

a와 b 사이의 시간 간격이 어떻게 되든, 프로세서 1은 대기할 것이다.

작업들 사이에 상호작용이 있다면 어떻게 될까? ==하나의 프로세서에 할당된 작업이 다른 프로세서에 할당된 작업의 결과를 필요로 한다면?== 예를 들어, 작업 1이 작업 4에 의존적인 경우는 어떻게 될까?


| 시간        | P1   | P2   |
| --------- | ---- | ---- |
|           | T1   | T2   |
| n+a       | (대기) | T2   |
| n+a+b     | (대기) | T4   |
| n+a+b+c   | T1   | (유휴) |
| n+a+b+c+d | T3   | (유휴) |

이 시나리오에서 프로세서 1은 작업 2와 4가 계산될 때가지 완전히 유휴(idle) 상태이다. 프로세서 1은 작업 1에서 대기 중이고 프로세서 2는 작업 2가 점유하고 있으므로, 프로세서 1이 대기 상태에서 벗어나기 위해 스스로 작업 4를 수행할 수도 있다.

이것은 FIFO 대기열이 도움이 될 수 있는 기본적인 부하 분산 문제와 같으므로 이렇게 해보자. ==대기열에 스케줄링된 작업들을 수행하는데,== ==각 프로세서는 처리 용량이 허용될 때 대기열에서 작업을 꺼내오고 그렇지 않으면 조인에서 대기한다.== 이것이 살펴볼 첫 번째 유형의 작업 가로체기 알고리즘이다. 이걸로 문제가 해결됐을까?


[그림]

그럴 수도 있다. 활용률이 낮은 프로세서로 인한 문제를 해결하기 때문에 프로세서들 사이에 작업을 나누는 것보다는 낫지만, 모든 프로세서가 사용해야만 하는 대기열이라는 중앙 집중식 데이터 구조를 도입했다. 30페이지의 "[[동시성 소개#메모리 접근 동기화|메모리 접근 동기화]]"에서 설명했듯이 임계 영역에 계속해서 들어가고 나오는 것은 비용이 많이 든다. 이뿐만 아니라 캐시의 지역성 문제도 악화됐다. ==이제는 작업을 대기열에 추가하거나 제거하기를 원할 때마다 중앙 집중식 대기열을 각 프로세서의 캐시에 로드한다.== 그럼에도 불구하고 세분화되지 않는 작업의 경우 이는 유효한 접근 방법이다. 그러나 ==고루틴은 대개 잘게 나누어져 있다.== 따라서 중앙 집중식 대기열은 작업 스케줄링 알고리즘에서 좋은 선택지가 될 수 없다.

다음으로 할 수 있는 도약은 작업 대기열을 분산시키는 것이다. 다음과 같이 각 프로세서에게 자체 스레드와 양쪽에서 넣고 뺄 수 있는 큐, 즉 데큐(deque)를 제공할 수 있다.


[그림]

높은 경쟁 하에서 중앙 집중식 데이터 구조에 대한 문제를 해결했지만, 캐시의 지역성 및 프로세서 활용과 관련된 문제는 어떤가? 이때 작업이 P1에서 시작되고 모든 포크(fork)된 작업이 P1의 대기열에 배치되면 P2에는 어떻게 작업이 이루어지는가? 그리고 작업이 대기열 사이에서 이동하기 때문에 이제는 컨텍스트 전환에 문제가 없어졌는가? 작업 가로채기 알고리즘과 분산 대기열이 함께 작동하는 방식에 대한 규칙을 살펴보겠다.


다시 한번 환기하자면, Go는 동시성을 위해 fork-join 모델을 따른다. 포크는 고루틴이 시작되는 시점, 합류 지점(join point)은 두 개 이상의 고루틴이 sync 패키지의 채널이나 타입을 통해 동기화되는 시점이다. **작업 가로채기 알고리즘**은 몇 가지 기본 규칙을 따른다.

1. 포그 지점에서 이 스레드와 연관된 데큐의 끝에 작업을 추가한다.
2. 스레드가 유휴 상태이면, 임의의 다른 스레드와 관련된 데큐의 앞(head)에서 작업을 가로챈다.
3. 아직 실현되지 않은 합류 지점(즉 아직 완료되지 않은 고루틴과 동기화)에서, 스레드 자체 데큐의 꼬리 부분을 제거한다.
4. 스레드의 데큐 양쪽이 모두 비어있는 경우,

a. 조인을 지연시킨다.
b. 임의의 스레드와 관련된 데큐의 앞 쪽에서 작업을 가로챈다.

이것은 약간 추상적이어서, 실제 코드를 살펴보면서 이 알고리즘을 실제로 살펴보자. 다음 프로그램은 피보나치 수열을 재귀적으로 계산한다.


``` go
package main

  

import (
    "fmt"
)

  

func main() {

  

    var fib func(n int) <-chan int
    fib = func(n int) <-chan int {
        result := make(chan int)

        go func() {
            defer close(result)
            if n <= 2 {
                result <- 1
                return
            }
            result <- <-fib(n-1) + <-fib(n-2)
        }()
        return result
    }
    fmt.Println("fib(4)=%d", <-fib(4))
}
```

이 Go 프로그램에서 이 버전의 작업 가로채기 알고리즘이 어떻게 작동하는지 살펴보겠다. 이 프로그램이 두 개의 단일 코어 프로세서가 있는 가상 머신에서 실행된다고 가정해보자. 각 프로세서에 하나의 OS 스레드씩, 프로세서 1에 대해 T1, 프로세서 2에 대해 T2를 생성한다. ==이 예제를 살펴보면서 몇 가지 구조를 제공하기 위해 T1에서 T2로 전환할 것이다.== 실제로 이 중 어느 것도 실행 시간이 사전에 결정돼 있지 않다.


이제 프로그램이 시작된다. 처음에는 main 고루틴 하나만 있으며, 프로세서 1에 스케줄링된 것으로 가정한다.


| T1 호출 스택   | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------- | -------- | -------- | -------- |
| (main 고루틴) |          |          |          |


다음으로 fib(4)의 호출에 도달한다. 이 고루틴은 T1의 작업 데큐의 꼬리에 스케줄링돼 위치할 것이고, 부모 고루틴은 연산을 계속할 것이다.


| T1 호출 스택   | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------- | -------- | -------- | -------- |
| (main 고루틴) | fib(4)   |          |          |

이 시점에서 타이밍에 따라 다음 두 가지 중 하나가 발생할 것이다. ==T1 또는 T2가 fib(4)에 대한 호출을 호스팅하는 고루틴을 가로챈다.== 이 예에서는 알고리즘을 보다 명확하게 설명하기 위해 T1이 작업을 가로채는데 성공했다고 가정하지만, ==두 스레드 중 어느 쪽이든 이길 수 있다는 점에 유의해야 한다.==


| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          |          |          |
| fib(4)                 |          |          |          |


fib(4)는 T1에서 실행되며, 추가된 작업은 왼쪽에서 오른쪽 순으로 이루어지므로 fib(4)가 호출된다.



| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) | fib(3)   |          |          |
| fib(4)                 | fib(2)   |          |          |

이 시점에서 T2는 여전히 유휴 상태이므로, T1 양방향 데큐의 헤드에서 fib(3)을 꺼내온다. 여기서 fib(4)가 마지막으로 대기열에 넣었으므로 ==T1이 가장 먼저 계산했어야 할 것 같은 fib(2)가 남아 있다는 것에 주목하자.== 이것이 중요한 이유에 대해서는 뒤에서 이야기 할 것이다.


| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) | fib(2)   | fib(3)   |          |
| fib(4)                 |          |          |          |
한편, T1은 fib(4)에서 작업을 계속할 수 없는 지점에 도달한다. fib(3) 및 fib(2)에서 반환된 채널을 기다리고 있다. 이것이 알고리즘의 3단계에서 미실현된 합류 지점이다. 이 때문에 자체 대기열의 꼬리 부분에서 작업을 꺼내오며, 여기서는 fib(2)이다.



| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | fib(3)   |          |
| fib(4) (미실현 합류 지점)     |          |          |          |
| fib(2)                 |          |          |          |

이 부분은 약간 혼란스럽다. 재귀 알고리즘에는 역추적(backtracking)을 사용하지 않으므로 fib(2)를 계산하기 위해 다른 고루틴을 스케줄링할 것이다. 이것은 T1에 막 스케줄링된 새롭고 분리된 고루틴이다. T1에 방금 스케줄링된 것은 fib(4) (즉, 4-2)에 대한 호출의 일부였다. 새로운 고루틴으 fib(3) (즉, 3-1)에 대한 호출을 일부이다. 여기는 fib(3)에 대한 호출에서 새롭게 스케줄링된 고루틴들이다.


| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | fib(3)   | fib(2)   |
| fib(4) (미실현 합류 지점)     |          |          | fib(1)   |
| fib(2)                 |          |          |          |

다음으로 T1은 재귀적으로 피보나치 알고리즘의 기저 사례(n<=2)에 도달하고 1을 리턴한다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | fib(3)   | fib(2)   |
| fib(4) (미실현 합류 지점)     |          |          | fib(1)   |
| (1 리턴)                 |          |          |          |

그 후에 T2는 미실현 합류 지점에 도달하고 자신의 데큐 꼬리에서 작업을 꺼내온다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택         | T2 작업 데큐 |
| ---------------------- | -------- | ---------------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | fib(3) (미실현합류지점) | fib(2)   |
| fib(4) (미실현 합류 지점)     |          | fib(1)           |          |
| (1 리턴)                 |          |                  |          |

이제 T1은 다시 유휴 상태가 되었으며, T2의 작업 데큐에서 작업을 가로챈다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택         | T2 작업 데큐 |
| ---------------------- | -------- | ---------------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | fib(3) (미실현합류지점) |          |
| fib(4) (미실현 합류 지점)     |          | fib(1)           |          |
| fib(2)                 |          |                  |          |

그러면 T2는 다시 한번 기저 사례(n <= 2)에 도달하고 1을 리턴한다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택         | T2 작업 데큐 |
| ---------------------- | -------- | ---------------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | fib(3) (미실현합류지점) |          |
| fib(4) (미실현 합류 지점)     |          | (1 리턴)           |          |
| fib(2)                 |          |                  |          |

다음으로 T1 역시 기저 사례에 도달하고 1을 리턴한다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택         | T2 작업 데큐 |
| ---------------------- | -------- | ---------------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | fib(3) (미실현합류지점) |          |
| fib(4) (미실현 합류 지점)     |          | (1 리턴)           |          |
| (1 리턴)                 |          |                  |          |

T2의 fib(3)에 대한 호출은 이제 두 개의 실현된 합류 지점을 가지고 있다. fib(2)와 fib(1)에 대한 호출 모두 자신들의 채널로 결과를 리턴했으며, 생성된 두 개의 고루틴들은 fib(3) 호출했던 자신들의 부모 고루틴과 합류(join)했다. 이 부모 고루틴은 덧셈(1+1=2)을 수행하고 그 결과를 자신의 채널로 리턴한다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          | (2 리턴)   |          |
| fib(4) (미실현 합류 지점)     |          |          |          |

동일한 일이 다시 일어난다. fib(4)에 대한 호출을 호스팅하는 고루틴은 fib(3)과 fib(2)라는 두 개의 미실현 합류 지점을 가지고 있다. 이전 단계에서 막 fib(3)에 대한 조인을 완료했으며, 마지막 작업 T2 가 완료되면서 fib(2)에 대한 조인이 완료됐다.

다시 덧셈 (2+1=3) 이 수행되고, 그 결과는 fib(4)의 채널로 리턴된다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (main 고루틴) (미실현 합류 지점) |          |          |          |
| (3 리턴)                 |          |          |          |


이 시점에서 main 고루틴에 대한 합류 지점(<-fib(4))이 실현되었으며, main 고루틴은 계속해서 실행될 수 있다. main 고루틴에 대한 결과를 출력한다.

| T1 호출 스택               | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------------------- | -------- | -------- | -------- |
| (3 리턴)                 |          |          |          |


이제 이 알고리즘의 다른 흥미로운 부분을 알아보자. 실행 스레드는 작업 데큐의 끝에 넣고 필요할 때마다 꺼낸다는 것을 떠올려보자. 데큐의 꼬리 쪽에 위치한 작업에는 몇 가지 흥미로운 속성이 있다.

- 부모의 조인을 완료하는데 가장 필요한 작업이다.

더 빠르게 조인을 완료한다는 것은 프로그램의 성능이 향상되고 메모리에 저장되는 항목이 적음을 의미한다.

- 프로세서의 캐시에 여전히 남아있을 가능성이 있는 작업이다.

스레드가 현재 작업을 수행하기 전에 마지막으로 수행한 작업이기 때문에, 스레드가 실행 중인 CPU의 캐시에 이 정보가 남아 있을 가능성이 높다. 즉, 캐시 누락(cache miss)가 적다는 의미이다.

전반적으로 이러한 방식으로 작업을 스케줄링하면 드러나지 않는 성능상의 이점이 많다.


---

### 작업 또는 연속 가로채기

대충 얼버무리고 넘어간 것 중 하나가 어떤 작업을 대기시키고 어떤 작업을 가로채는지에 대한 질문이다. 포크-조인 패러다임에서는 두 가지 옵션, 즉 작업(task)과 연속(continuation)이 있다. Go에서 작업과 연속이 무엇인지 명확하게 이해하기 위해서 피보나치 프로그램을 다시 살펴보자.


``` go
package main

import (
    "fmt"
)

  

func main() {

  

    var fib func(n int) <-chan int
    fib = func(n int) <-chan int {
        result := make(chan int)

        go func() { // #1

            defer close(result)

            if n <= 2 {
                result <- 1
                return
            }

            result <- <-fib(n-1) + <-fib(n-2)
        }()
        return result // #2
    }
    fmt.Println("fib(4)=%d", <-fib(4))
}
```


1. Go에서 고루틴은 작업이다.
2. 고루틴이 호출된 이후의 모든 것은 연속이다.

==분산 대기열 작업 가로채기 알고리즘에 관한 이전의 예제에서 작업이나 고루틴을 대기열에 넣었다.== 고루틴이 작업의 내용을 깔끔하게 캡슐화하는 함수를 호스팅하기 때문에, 이 방식은 자연스럽다. 그러나 이것이 실제로 Go의 작업 가로채기 알고리즘이 작동하는 방식은 아니다. Go의 작업 가로채기 알고리즘은 연속을 대기열에 넣고 가로챈다.

그렇다면 이 문제가 왜 중요할까? ==연속을 대기열에 넣고 가로채는 경우에 작업을 큐에 넣고 가로채는 것에 비해 추가적으로 발생하는 일들은 무엇일까?== 이 질문에 대답하기 위해 합류 지점을 살펴보자.

알고리즘에 따르면, 실행 스레드가 실현되지 않은 합류 지점에 도달하면 스레드는 실행을 일시 중지하고 작업의 가로채기를 수행해야 한다. 작업이 수행되는 동안 조인이 뒤로 미뤄지기 때문에 이를 조인 지연이라고 한다. 작업 가로채기와 연속 가로채기 알고리즘은 둘 다 조인을 지연시키지만, 지연이 얼마나 자주 발생하는지에는 상당한 차이가 있다.

다음을 생각해보자. ==고루틴을 생성할 때는, 프로그램에서 그 고루틴의 함수를 실행하기를 원할 것이다.== ==또한 그 고루틴 뒤쪽의 연속은 어떤 시점에서 그 고루틴과 조인하기를 원할 것이다.== ==그리고 고루틴이 완료되기 전에 그 뒤에서 조인을 시도하는 것이 드물 일은 아니다. ==이 근본 명제를 감안한다면, 고루틴을 스케줄링할 때 즉시 작업을 시작하는 것이 합리적이다.

이제 데큐의 꼬리 쪽에 작업을 넣거나 꼬리 쪽에서 작업을 꺼내오는 스레드와 머리 쪽에서 작업을 꺼내오는 스레드의 속성에 대해 생각해보자. ==데큐의 꼬리 쪽에 연속을 집어넣는다면, 데큐의 머리 쪽에서 꺼내가는 스레드에게 가로채기 당할 가능성이 거의 없으며, 고루틴이 실행을 끝내면 이를 다시 꺼내올 수 있고 지연을 피할 수 있다.== ==또한 포크된 태스크를 함수 호출과 비슷하게 보이도록 만든다.== 스레드는 고루틴의 실행으로 건너뛰고 완료 후 그 연속으로 리턴한다.

피보나치 프로그램에 연속 가로채기를 적용하는 방법을 살펴보자. 연속을 표현하는 것은 작업을 표현하는 것보다 덜 명확하기 때문에 다음과 같은 규칙을 사용한다.

- 작업 데큐에 연속이 들어왔을 때 그것을 X의 연속으로 표시한다.
- 연속이 실행을 위해 대기열에서 꺼내지면 암묵적으로 연속을 fib의 다음 호출로 변환한다.

다음은 Go의 런타임이 수행하는 작업을 더 자세히 보여준다.

다시 한번 main 고루틴에서 시작한다.


| T1 호출 스택   | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| ---------- | -------- | -------- | -------- |
| (main 고루틴) |          |          |          |

main 고루틴은 fib(4)를 호출하고, 이 호출의 연속은 T1의 작업 데큐 꼬리 쪽에 들어간다.

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| -------- | -------- | -------- | -------- |
| fib(4)   | main의 연속 |          |          |

T2는 유휴 상태이므로 main의 연속을 가로챈다.

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택 | T2 작업 데큐 |
| -------- | -------- | -------- | -------- |
| fib(4)   |          | main의 연속 |          |


fib(4)는 fib(3)을 T1의 호출 스택에 스케줄링하는데, 이 fib(3)은 바로 실행되고 fib(4)의 연속이 T1의 작업 데큐 뒤쪽에 추가된다.

| T1 호출 스택 | T1 작업 데큐   | T2 호출 스택 | T2 작업 데큐 |
| -------- | ---------- | -------- | -------- |
| fib(3)   | fib(4)의 연속 | main의 연속 |          |


T2가 main의 연속을 실행하려고 시도할 때 T2는 **미실현 합류 지점**에 도달하게 되고 T1의 다른 작업들을 가로챈다. 이번에도 가로채는 것은 fib(4)의 연속이다.

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택             | T2 작업 데큐 |
| -------- | -------- | -------------------- | -------- |
| fib(3)   |          | main의 연속 (미실현 합류 지점) |          |
|          |          | fib(4)의 연속           |          |

다음으로 T1의 fib(3)에 대한 호출은 fib(2)를 위한 고루틴을 스케줄링 하는데, T1은 이 fib(2)를 바로 실행하기 시작한다. fib(3)의 연속은 T1의 작업 데큐 뒤쪽에 들어간다.

| T1 호출 스택 | T1 작업 데큐   | T2 호출 스택   | T2 작업 데큐 |
| -------- | ---------- | ---------- | -------- |
| fib(2)   | fib(3)의 연속 | main의 연속   |          |
|          |            | fib(4)의 연속 |          |

fib(4)의 연속에 대한 T2의 실행은 T1이 남겨두고 간 지점에서 계속되며, fib(2)를 스케줄링해 즉시 실행하기 시작한다. 그리고 다시 fib(4)를 데큐에 넣는다.

| T1 호출 스택 | T1 작업 데큐   | T2 호출 스택 | T2 작업 데큐   |
| -------- | ---------- | -------- | ---------- |
| fib(2)   | fib(3)의 연속 | main의 연속 | fib(4)의 연속 |
|          |            | fib(2)   |            |


다음으로 fib(2)에 대한 T1의 호출은 우리 재귀 알고리즘의 기저 사례에 도달하게 되고, 1을 리턴한다.


| T1 호출 스택 | T1 작업 데큐   | T2 호출 스택             | T2 작업 데큐   |
| -------- | ---------- | -------------------- | ---------- |
| (1을 리턴)  | fib(3)의 연속 | main의 연속 (미실현 합류 지점) | fib(4)의 연속 |
|          |            | fib(2)               |            |

그러면 T2도 기저 사례에 도달하고 마찬가지로 1을 리턴한다.

| T1 호출 스택 | T1 작업 데큐   | T2 호출 스택             | T2 작업 데큐   |
| -------- | ---------- | -------------------- | ---------- |
| (1을 리턴)  | fib(3)의 연속 | main의 연속 (미실현 합류 지점) | fib(4)의 연속 |
|          |            | (1을 리턴)              |            |

그 다음으로 T1은 자신의 대기열에서 작업을 가로채서 fib(1)을 계산하기 시작한다. T1의 콜 체인이 fib(3)-> fib(2) ->fib(1)가 되는 방식을 주목하라. 이게 바로 앞서 논의한 연속 가로채기의 이점이다!

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택             | T2 작업 데큐   |
| -------- | -------- | -------------------- | ---------- |
| fib(1)   |          | main의 연속 (미실현 합류 지점) | fib(4)의 연속 |
|          |          | (1을 리턴)              |            |

T2는 fib(4)의 연속의 끝에 위치하지만, fib(2)라는 하나의 합류 지점만 실현된다. fib(3)에 대한 호출은 여전히 T1에서 처리되고 있다. 더 이상 가로챌 작업이 없으므로 T2는 유휴 상태이다.

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택               | T2 작업 데큐 |
| -------- | -------- | ---------------------- | -------- |
| fib(1)   |          | main의 연속 (미실현 합류 지점)   |          |
|          |          | fib(4)의 연속 (미실현 합류 지점) |          |

T1은 이제 연속인 마지막인 fib(3)에 도달했으며, 합류 지점인 fib(2)와 fib(1)도 만족됐다. T1은 2를 리턴한다.

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택             | T2 작업 데큐 |
| -------- | -------- | -------------------- | -------- |
| (2를 리턴)  |          | main의 연속 (미실현 합류 지점) |          |
|          |          | (2를 리턴)              |          |


이제 fib(4)의 합류 지점인 fib(3)와 fib(2)도 만족됐다. T2는 계산을 수행할 수 있으며, 그 결과(2+1=3)을 리턴한다.

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택             | T2 작업 데큐 |
| -------- | -------- | -------------------- | -------- |
|          |          | main의 연속 (미실현 합류 지점) |          |
|          |          | (3를 리턴)              |          |


마침내 main 고루틴의 합류 지점이 실현되었으며 fib(4)의 호출 결과를 받아서 4를 출력할 수 있게 됐다.

| T1 호출 스택 | T1 작업 데큐 | T2 호출 스택     | T2 작업 데큐 |
| -------- | -------- | ------------ | -------- |
|          |          | main (3를 리턴) |          |


이렇게 추적해보면, T1에서 연속적으로 연산이 실행되도록 하기 위해 어떤 식으로 연속을 활용하는지 간략히 알 수 있다. 연속 가로채기를 사용한 이번 실행과 작업 가로채기를 사용한 실행의 통계를 비교한다면 그 이점이 좀 더 명확하게 드러날 것이다.


| 통계 지표      | 연속 가로채기      | 작업 가로채기         |
| ---------- | ------------ | --------------- |
| 단계의 수      | 14           | 15              |
| 데큐의 최대 길이  | 2            | 2               |
| 지연된 조인의 횟수 | 2(모두 유휴 스레드) | 3(모두 작업 중인 스레드) |
| 호출 스택의 크기  | 2            | 3               |


이러한 통계 지표는 비슷해 보일 수 있지만 큰 시스템을 대상으로 추론한다면 연속 가로채기가 얼마나 확실하게 이득인지 실감할 수 있다.

또한 오직 하나의 실행 스레드만 있을 경우에 이 실행이 어떻게 되는지도 살펴보자.


| T1 호출 스택 | T1 작업 데큐 |
| -------- | -------- |
| main     |          |

| T1 호출 스택 | T1 작업 데큐 |
| -------- | -------- |
| fib(4)   | main     |


| T1 호출 스택 | T1 작업 데큐   |
| -------- | ---------- |
| fib(3)   | main       |
|          | fib(4)의 연속 |


| T1 호출 스택 | T1 작업 데큐   |
| -------- | ---------- |
| fib(3)   | main       |
|          | fib(4)의 연속 |
|          | fib(3)의 연속 |

| T1 호출 스택 | T1 작업 데큐   |
| -------- | ---------- |
| (1을 리턴)  | main       |
|          | fib(4)의 연속 |
|          | fib(3)의 연속 |

| T1 호출 스택 | T1 작업 데큐   |
| -------- | ---------- |
| fib(1)   | main       |
|          | fib(4)의 연속 |

| T1 호출 스택 | T1 작업 데큐   |
| -------- | ---------- |
| (1을 리턴)  | main       |
|          | fib(4)의 연속 |

| T1 호출 스택 | T1 작업 데큐   |
| -------- | ---------- |
| (2를 리)   | main       |
|          | fib(4)의 연속 |


| T1 호출 스택 | T1 작업 데큐 |
| -------- | -------- |
| fib(2)   | main     |


| T1 호출 스택 | T1 작업 데큐 |
| -------- | -------- |
| (1을 리턴)  | main     |


| T1 호출 스택 | T1 작업 데큐 |
| -------- | -------- |
| (3을 리턴)  | main     |


| T1 호출 스택    | T1 작업 데큐 |
| ----------- | -------- |
| main(3을 리턴) |          |


흥미롭다! ==고루틴을 사용한 단일 스레드의 런타임은 함수를 사용한 것과 동일하다!== 이것이 연속 가로채기의 또 다른 이점이다.

이 모든 것은 고려하면, ==연속을 가로채는 것이 이론적으로 작업을 가로채는 것보다 훨씬 우월하다는 점을 알 수 있으므로 고루틴이 아닌 연속을 대기열에 넣는 것이 가장 좋다.== 다음 표에서 볼 수 있듯이 연속을 가로채는 것에는 여러 가지 이점이 있다.


|        | 연속    | 자식  |
| ------ | ----- | --- |
| 대기열 크기 | 제한    | 무제한 |
| 실행의 순서 | 순차적   | 무작위 |
| 합류 지점  | 지연 없음 | 지연  |

그렇다면 왜 모든 작업 가로채기 알고리즘을 연속 가로채기로 구현하지 않는 걸까? 연속 가로채기는 여전히 컴파일러의 지원을 필요로 한다. 운 좋게도 Go는 자체 컴파일러가 있으며, 연속 가로채기는 Go의 작업 가로채기 알고리즘이 구현되는 방식이다. 이러한 고급스러움이 없는 언어는 대개 라이브러리로, 흔히 "**자식**"이라고 하는 작업 가로채기를 구현한다.


이 모델은 Go의 알고리즘에 더 가깝지만, 전체 그림을 나타내는 것은 아니다. Go는 추가적인 최적화를 수행한다. 이를 분석하기 전에 소스 코드에 Go 스케줄러의 명명법을 사용하기 시작하는 것으로 단계를 설정해 보겠다.

Go의 스케줄러는 세 가지 메인 컨셉을 가지고 있다.

- G

고루틴

- M

OS의 스레드(소스코드에서는 기기(machine)로 언급되기도 한다)

- P
컨텍스트(소스코드에서는 프로세서(processor)로 언급되기도 한다)




작업 가로채기에 대한 논의에서 M은 T와 같으며 P는 작업 데큐와 동일하다 (GOMAXPROCS가 변경되면 할당되는 개수가 변경된다). G는 고루틴이지만 goroutine의 현 상태, 특히 대표적으로 프로그램 카운터(PC)를 나타낸다는 점에 유의하자. 이를 통해 G는 연속을 나타낼 수 있으며 Go는 연속 가로채기를 할 수 있다.

Go의 런타임에는 M이 시작되고 M이 P를 호스트한 다음, P는 G를 스케줄링하고 호스트한다.


[그림]


이 표기법만 사용하는 경우 이 알고리즘이 어떻게 작동하는지 분석하기가 어렵기 때문에, 이번 분석에서는 전체 이름을 사용할 것이다. 좋다. 이제 용어가 정해졌으므로 Go의 스케줄러가 어떻게 작동하는지 살펴보자!

앞서 언급했듯이, GOMAXPROCS 설정은 런타임에서 사용할 수 있는 컨텍스트 수를 제어한다. 기본 설정은 호스트 시스템의 논리 CPU당 하나의 컨텍스트가 존재하는 것이다. 컨텍스트와는 다르게, Go의 런타임이 가비지 컬렉션 및 고루틴 등을 관리하는데 도움이 되는 OS 스레드는 코어보다 더 많거나 적을 수 있다. 사실 런타임이 보장하는 매우 중요한 사실이 하나 있기 때문에 이 이야기를 꺼낸 것이다. 바로 적어도 모든 컨텍스트를 호스팅 처리할 수 있을 만큼 충분한 OS 스레드가 언제나 존재한다는 점이다. 이로 인해 런타임은 중요한 최적화를 수행할 수 있다. 런타임은 현재 사용되지 않는 스레드에 대한 스레드 풀도 포함한다. 이제 최적화에 대해 이야기해보자!

이 상황에서 Go는, OS 스레드에서 컨텍스트를 분리해 컨텍스트를 대기 상태가 아닌 다른 OS 스레드로 넘겨줄 수 있다. ==이렇게 하면 컨텍스트가 추가적인 고루틴을 스케줄링할 수 있으므로, 런타임은 호스트 시스템의 CPU를 활성 상태로 유지할 수 있다.== 차단된 고루틴은 차단된 스레드와 관련이 있다.

==고루틴이 차단 해제되면 호스트 OS의 스레드는 이전에 차단했던 고루틴을 계속 실행할 수 있도록, 다른 OS 스레드 중 하나에서 컨텍스트를 가로채려고 시도한다.== 그러나 이것이 항상 가능한 것은 아니다. ==컨텍스트 가로채기가 불가능한 경우, 스레드는 전역 컨텍스트에 고루틴을 배치하고 해당 스레드는 절전 모드로 전환되며==, ==나중에 고루틴이 다시 차단되는 경우가 발생한 경우 등에 사용할 수 있도록 런타임 스레드 풀에 배치된다.==

방금 언급한 전역 컨텍스트는 추상적인 작업 가로채기 알고리즘에 대해 앞서 이야기한 내용과 부합하지 않는다. 이는 Go가 CPU 사용을 최적화하는 방법에 따라 필요한 구현상의 세부 사항이다. 전역 컨텍스트에 배치되는 고루틴이 영원히 거기 머물지 않도록 하려면 몇 가지 추가적인 단계가 작업 가로채기 알고리즘에 추가돼야 한다. ==주기적으로 컨텍스트는 전역 컨텍스트를 검사해 거기에 고루틴이 있는지 확인하고==, ==컨텍스트의 큐가 비어 있으면 다른 OS 스레드의 컨텍스트를 확인하기 전에 먼저 전역 컨텍스트에서 가져올 작업이 있는지 확인해야 한다.==

입력/출력 및 시스템 콜 외에 Go는 함수 호출 중에도 고루틴이 선점 될 수 있게 한다. 이는 런타임이 효율적으로 작업을 스케줄링할 수 있도록 해주며, 매우 정교한 동시 작업을 선호하는 Go의 철학에 맞춰 작동한다. Go 개발팀이 해결하려고 한 주목할 만한 예외가 있다(htttps://github.com/golang/go/issues/10958). 바로 입력/출력 시스템 콜, 함수 호출을 수행하지 않는 고루틴이다. 현재 이러한 종류의 고루틴은 선점 가능하지 않으며, 긴 가비지 컬렉션 대기, 심지어는 같은 중요한 문제를 일으킬 수 있다. 경험으로 미루어 보아 이런 일은 거의 발생하지 않는다.

---
# 이 모든 것을 개발자에게 보여주는 방법

고루틴이 어떻게 작동하는지 이해했으므로 이제 뒤로 물러나서, 이 모든 것을 개발자와 인터페이스하는 방식을 통해 다시 반복해보겠다. 그것은 바로 go 키워드다. 이게 전부다.


함수나 클로저 앞에 go라는 단어를 치면, 실행 중인 컴퓨터에서 가장 효율적인 방식으로 실행될 작업이 자동으로 스케줄링된다. 개발자로서 우리는 여전히 우리가 잘 알고 있는 기본 요소인 함수를 기반으로 생각하고 있다. 우리는 일을 하는 새로운 방식, 복잡한 데이터 구조 또는 스케줄링 알고리즘을 이해할 필요가 없다.

확장성, 효율성, 단순성. 이것이 고루틴을 매우 흥미롭게 만드는 특징이다.